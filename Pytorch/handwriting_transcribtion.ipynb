{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQDnOljOkTLT"
      },
      "source": [
        "!wget https://www.dropbox.com/s/l2ul3upj7dkv4ou/synthetic-data.zip\n",
        "!unzip -qq synthetic-data.zip\n",
        "\n",
        "# each image is located in folder synthetic-data\n",
        "# example image name (annotation) is according what is whitten on image:\n",
        "# on this image is written word \"American\" : /content/synthetic-data/American@3WPOqS.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1IOQ7q9kX6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "025ec192-684b-4a02-b94e-87d9a63593f8"
      },
      "source": [
        "!pip install livelossplot --quiet\n",
        "from livelossplot import PlotLosses\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import os\n",
        "from glob import glob\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 36.4 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 43.8 MB/s eta 0:00:01\r\u001b[K     |▉                               | 40 kB 48.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 52.8 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61 kB 57.4 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71 kB 50.0 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81 kB 51.0 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 92 kB 52.1 MB/s eta 0:00:01\r\u001b[K     |██                              | 102 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 112 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 122 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 133 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 143 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 153 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 163 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 174 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 184 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████                            | 194 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 204 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 215 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 225 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 235 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 245 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 256 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 266 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 276 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 286 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 296 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 307 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 317 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 327 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 337 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 348 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 358 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 368 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 378 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 389 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 399 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 409 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 419 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 430 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 440 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 450 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 460 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 471 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 481 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 491 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 501 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 512 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 522 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 532 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 542 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 552 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 563 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 573 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 583 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 593 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 604 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 614 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 624 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 634 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 645 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 655 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 665 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 675 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 686 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 696 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 706 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 716 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 727 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 737 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 747 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 757 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 768 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 778 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 788 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 798 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 808 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 819 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 829 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 839 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 849 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 860 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 870 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 880 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 890 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 901 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 911 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 921 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 931 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 942 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 952 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 962 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 972 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 983 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 993 kB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.0 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.0 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.0 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.0 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.0 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.1 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.1 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.1 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.1 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.1 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.1 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.1 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.2 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.2 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.2 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.2 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.2 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.2 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.2 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.2 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.3 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.3 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.3 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.3 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.3 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.3 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.3 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.3 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.4 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.4 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.4 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.4 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.4 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.4 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.5 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.5 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.5 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.5 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.5 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.5 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.5 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.6 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6 MB 54.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6 MB 54.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Levenstein Distance\n",
        "\n",
        "\n",
        "## got help from here: https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/#:~:text=The%20Levenshtein%20distance%20is%20a,transform%20one%20word%20into%20another.\n",
        "\n",
        "\n",
        "# def printDistances(distances, token1Length, token2Length):\n",
        "#     for t1 in range(token1Length + 1):\n",
        "#         for t2 in range(token2Length + 1):\n",
        "#             print(int(distances[t1][t2]), end=\" \")\n",
        "#         print()\n",
        "\n",
        "def levenshteinDistanceDP(token1, token2):\n",
        "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
        "\n",
        "    for t1 in range(len(token1) + 1):\n",
        "        distances[t1][0] = t1\n",
        "\n",
        "    for t2 in range(len(token2) + 1):\n",
        "        distances[0][t2] = t2\n",
        "        \n",
        "    a = 0\n",
        "    b = 0\n",
        "    c = 0\n",
        "    \n",
        "    for t1 in range(1, len(token1) + 1):\n",
        "        for t2 in range(1, len(token2) + 1):\n",
        "            if (token1[t1-1] == token2[t2-1]):\n",
        "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
        "            else:\n",
        "                a = distances[t1][t2 - 1]\n",
        "                b = distances[t1 - 1][t2]\n",
        "                c = distances[t1 - 1][t2 - 1]\n",
        "                \n",
        "                if (a <= b and a <= c):\n",
        "                    distances[t1][t2] = a + 1\n",
        "                elif (b <= a and b <= c):\n",
        "                    distances[t1][t2] = b + 1\n",
        "                else:\n",
        "                    distances[t1][t2] = c + 1\n",
        "\n",
        "    #printDistances(distances, len(token1), len(token2))\n",
        "    return distances[len(token1)][len(token2)]\n",
        "\n",
        "## test\n",
        "#levenshteinDistanceDP('ladooo', 'laaado') "
      ],
      "metadata": {
        "cellView": "form",
        "id": "vBvZ6ieymui3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5ImW_I4kb3Z",
        "cellView": "form"
      },
      "source": [
        "#@title data handling\n",
        "\n",
        "\n",
        "images = glob('./synthetic-data/*.png')\n",
        "imagelabels = lambda fname: fname.split(\"/\")[-1].split('@')[0]\n",
        "\n",
        "vocab = 'QWERTYUIOPASDFGHJKLZXCVBNMqwertyuiopasdfghjklzxcvbnm'\n",
        "B,T,V = 64, 32, len(vocab) \n",
        "H,W = 32, 128 \n",
        "\n",
        "class OCRDataset(Dataset):\n",
        "    def __init__(self, items, vocab=vocab, preprocess_shape=(H,W), timesteps=T):\n",
        "        super().__init__()\n",
        "        self.items = items\n",
        "        self.charList = {ix+1:ch for ix,ch in enumerate(vocab)}\n",
        "        self.charList.update({0: '`'})\n",
        "        self.invCharList = {v:k for k,v in self.charList.items()}\n",
        "        self.ts = timesteps\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "    def sample(self):\n",
        "        return self[random.randint(0, len(self))]\n",
        "    def __getitem__(self, ix):\n",
        "        item = self.items[ix]\n",
        "        image = cv2.imread(item, 0)\n",
        "        label = imagelabels(item)\n",
        "        return image, label\n",
        "    def collate_fn(self, batch):\n",
        "        images, labels, label_lengths, label_vectors, input_lengths = [], [], [], [], []\n",
        "        for image, label in batch:\n",
        "            images.append(torch.Tensor(self.preprocess(image))[None,None])\n",
        "            label_lengths.append(len(label))\n",
        "            labels.append(label)\n",
        "            label_vectors.append(self.str2vec(label))\n",
        "            input_lengths.append(self.ts)\n",
        "        images = torch.cat(images).float().to(device)\n",
        "        label_lengths = torch.Tensor(label_lengths).long().to(device)\n",
        "        label_vectors = torch.Tensor(label_vectors).long().to(device)\n",
        "        input_lengths = torch.Tensor(input_lengths).long().to(device)\n",
        "        return images, label_vectors, label_lengths, input_lengths, labels\n",
        "    def str2vec(self, string, pad=True):\n",
        "        string = ''.join([s for s in string if s in self.invCharList])\n",
        "        val = list(map(lambda x: self.invCharList[x], string)) \n",
        "        if pad:\n",
        "            while len(val) < self.ts:\n",
        "                val.append(0)\n",
        "        return val\n",
        "    def preprocess(self, img, shape=(32,128)):\n",
        "        target = np.ones(shape)*255\n",
        "        try:\n",
        "            H, W = shape\n",
        "            h, w = img.shape\n",
        "            fx = H/h\n",
        "            fy = W/w\n",
        "            f = min(fx, fy)\n",
        "            _h = int(h*f)\n",
        "            _w = int(w*f)\n",
        "            _img = cv2.resize(img, (_w,_h))\n",
        "            target[:_h,:_w] = _img\n",
        "        except:\n",
        "            ...\n",
        "        return (255-target)/255\n",
        "    def decoder_chars(self, pred):\n",
        "        decoded = \"\"\n",
        "        last = \"\"\n",
        "        pred = pred.cpu().detach().numpy()\n",
        "        for i in range(len(pred)):\n",
        "            k = np.argmax(pred[i])\n",
        "            if k > 0 and self.charList[k] != last:\n",
        "                last = self.charList[k]\n",
        "                decoded = decoded + last\n",
        "            elif k > 0 and self.charList[k] == last:\n",
        "                continue\n",
        "            else:\n",
        "                last = \"\"\n",
        "        return decoded.replace(\" \",\" \")\n",
        "    def wer(self, preds, labels):\n",
        "        c = 0\n",
        "        for p, l in zip(preds, labels):\n",
        "            c += p.lower().strip() != l.lower().strip()\n",
        "        return round(c/len(preds), 4)\n",
        "    def cer(self, preds, labels):\n",
        "        c, d = [], []\n",
        "        for p, l in zip(preds, labels):\n",
        "            c.append(levenshteinDistanceDP(p, l) / len(l))   \n",
        "        return round(np.mean(c), 4)\n",
        "    def evaluate(self, model, ims, labels, lower=False):\n",
        "        model.eval()\n",
        "        preds = model(ims).permute(1,0,2) # B, T, V+1\n",
        "        preds = [self.decoder_chars(pred) for pred in preds]\n",
        "        return {'char-error-rate': self.cer(preds, labels),\n",
        "                'word-error-rate': self.wer(preds, labels),\n",
        "                'char-accuracy' : 1 - self.cer(preds, labels),\n",
        "                'word-accuracy' : 1 - self.wer(preds, labels)}\n",
        "\n",
        "\n",
        "trn_items, val_items = train_test_split(images, test_size=0.2, random_state=22)\n",
        "trn_ds = OCRDataset(trn_items)\n",
        "val_ds = OCRDataset(val_items)\n",
        "\n",
        "trn_dl = DataLoader(trn_ds, batch_size=B, collate_fn=trn_ds.collate_fn, drop_last=True, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=B, collate_fn=val_ds.collate_fn, drop_last=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3K_qrPek42x",
        "cellView": "form"
      },
      "source": [
        "#@title model\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, ni, no, ks=3, st=1, padding=1, pool=2, drop=0.2):\n",
        "        super().__init__()\n",
        "        self.ks = ks\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(ni, no, kernel_size=ks, stride=st, padding=padding),\n",
        "            nn.BatchNorm2d(no, momentum=0.3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(pool),\n",
        "            nn.Dropout2d(drop)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class Ocr(nn.Module):\n",
        "    def __init__(self, vocab):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            BasicBlock( 1, 128),\n",
        "            BasicBlock(128, 128),\n",
        "            BasicBlock(128, 256, pool=(4,2)),\n",
        "        )\n",
        "        self.rnn = nn.Sequential(\n",
        "            nn.LSTM(256, 256, num_layers=2, dropout=0.2, bidirectional=True),\n",
        "        )\n",
        "        self.classification = nn.Sequential(\n",
        "            nn.Linear(512, vocab+1),\n",
        "            nn.LogSoftmax(-1),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        x = x.view(-1, 256, 32)    # x.reshape(-1, 256, 32)\n",
        "        x = x.permute(2, 0, 1)       \n",
        "        x, lstm_states = self.rnn(x)\n",
        "        y = self.classification(x)\n",
        "        return y"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zmJcfsklpl8",
        "cellView": "form"
      },
      "source": [
        "#@title training\n",
        "\n",
        "def ctc(log_probs, target, input_lengths, target_lengths, blank=0):\n",
        "    loss = nn.CTCLoss(blank=blank, zero_infinity=True)\n",
        "    ctc_loss = loss(log_probs, target, input_lengths, target_lengths)\n",
        "    return ctc_loss\n",
        "\n",
        "def train_batch(data, model, optimizer, criterion):\n",
        "    model.train()\n",
        "    imgs, targets, label_lens, input_lens, labels = data\n",
        "    optimizer.zero_grad()\n",
        "    preds = model(imgs)\n",
        "    loss = criterion(preds, targets, input_lens, label_lens)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    results = trn_ds.evaluate(model, imgs.to(device), labels)\n",
        "    return loss, results\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate_batch(data, model):\n",
        "    model.eval()\n",
        "    imgs, targets, label_lens, input_lens, labels = data\n",
        "    preds = model(imgs)\n",
        "    loss = criterion(preds, targets, input_lens, label_lens)\n",
        "    return loss, val_ds.evaluate(model, imgs.to(device), labels)    \n",
        "\n",
        "###-------------------------------- define -----------------------------------\n",
        "model = Ocr(len(vocab)).to(device)\n",
        "criterion = ctc\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-3)\n",
        "n_epochs = 50\n",
        "\n",
        "###----------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def train_model(model, trn_dl, val_dl, optimizer, criterion, nepochs=n_epochs, eval_every=len(trn_dl), out_dir='./'):\n",
        "  \n",
        "  liveloss = PlotLosses()   # to plot training progress\n",
        "\n",
        "  history = {'trn_loss': None, 'trn_char_acc': None, 'trn_word_acc': None,\n",
        "            'val_loss': None, 'val_char_acc': None, 'val_word_acc': None}\n",
        "  losses = {'loss': None,\n",
        "          'val_loss': None}\n",
        "\n",
        "  best = float('inf')    # set to infinite initially\n",
        "  it = 0\n",
        "  for epoch in range(nepochs):\n",
        "\n",
        "    history['trn_loss'], history['trn_char_acc'], history['trn_word_acc']   = [], [], []       # initialize emtpy container for training losses\n",
        "    history['val_loss'], history['val_char_acc'], history['val_word_acc']   = [], [], [] \n",
        "\n",
        "    losses['loss'], losses['val_loss'] = [], []\n",
        "\n",
        "    for _, data in enumerate(trn_dl):\n",
        "      it += 1\n",
        "\n",
        "      loss, results = train_batch(data, model, optimizer, criterion)\n",
        "      # scheduler.step()\n",
        "      ca, wa = results['char-accuracy'], results['word-accuracy']\n",
        "      history['trn_loss'].append(loss.detach().cpu())\n",
        "      history['trn_char_acc'].append(ca)\n",
        "      history['trn_word_acc'].append(wa)\n",
        "\n",
        "      if (it == 1) or (it % eval_every == 0):\n",
        "        \n",
        "        with torch.no_grad():\n",
        "          average_val_loss = []\n",
        "          average_char_loss = []\n",
        "          average_word_loss = []\n",
        "\n",
        "          for _, data in enumerate(val_dl):\n",
        "              loss, results = validate_batch(data, model)\n",
        "              ca, wa = results['char-accuracy'], results['word-accuracy']\n",
        "              history['val_loss'].append(loss), \n",
        "              history['val_char_acc'].append(ca), history['val_word_acc'].append(wa)\n",
        "              \n",
        "              average_val_loss.append(loss)    # use average_val_loss.extend(...) if loss is itself listlike etc\n",
        "              average_char_loss.append(ca)\n",
        "              average_word_loss.append(wa)\n",
        "\n",
        "          average_val_loss = torch.stack(average_val_loss).mean().item()\n",
        "          average_char_loss = np.mean(average_char_loss)\n",
        "          average_word_loss = np.mean(average_word_loss)\n",
        "\n",
        "          if (average_val_loss + average_char_loss + average_word_loss) < best:     # keep track of best model\n",
        "            best = (average_val_loss + average_char_loss + average_word_loss)\n",
        "            torch.save(model.state_dict(), os.path.join(out_dir, 'model_best.pt'))  # save best model\n",
        "\n",
        "    # update liveplot with latest values\n",
        "    losses['val_loss'] = average_val_loss\n",
        "    lower_bound = it-(len(trn_dl)*(epoch+1))\n",
        "    part = history['trn_loss'][lower_bound : it]\n",
        "    losses['loss'] = np.mean(part)    #sum(part)/len(part) # average over all training losses\n",
        "\n",
        "    liveloss.update(losses)\n",
        "    liveloss.send()\n",
        "\n",
        "train_model(model, trn_dl, val_dl, optimizer, criterion, nepochs=10, eval_every=len(trn_dl), out_dir='./')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDpczoK0lvcu"
      },
      "source": [
        "## torch.save(model.state_dict(), './saved_model.pth') --> you do not need this because you already saved model versions.\n",
        "model = Ocr(len(vocab)).to(device)\n",
        "model.load_state_dict(torch.load('./model_best.pt'))\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## if you want to take generally any random image\n",
        "# for jx in range(5):\n",
        "#     img, label = val_ds.sample()\n",
        "#     _img = torch.Tensor(val_ds.preprocess(img)[None,None]).to(device)\n",
        "#     pred = model(_img)[:,0,:]\n",
        "#     pred = trn_ds.decoder_chars(pred)\n",
        "#     print(f'Pred: `{pred}` :: Truth: `{label}`')\n",
        "\n",
        "def predict(item):\n",
        "    img = cv2.imread(item, 0)\n",
        "    label = imagelabels(item)\n",
        "    _img = torch.Tensor(val_ds.preprocess(img)[None,None]).to(device)\n",
        "    pred = model(_img)[:,0,:]\n",
        "    pred = trn_ds.decoder_chars(pred)\n",
        "    print(f'Pred: `{pred}` :: Truth: `{label}`')\n",
        "\n",
        "predict('./synthetic-data/American@3WPOqS.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_KmF8TIAB7U",
        "outputId": "dbed2456-7d94-4418-d17b-d3aec99b7a62"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: `american` :: Truth: `American`\n"
          ]
        }
      ]
    }
  ]
}