{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmB-SwhGflKC"
      },
      "source": [
        "\n",
        "R E F E R E N C E\n",
        "\n",
        "CenterNet detects the center of the objects and finds everithing else (size or offsets of the object) based on regression (between ground truth and predicted heatmaps-created via gaussian).\n",
        "But downside is also caused by this feature. Downside is that we cannot really make very accurate instance segmentations.\n",
        "\n",
        "Paper : https://arxiv.org/pdf/1904.07850.pdf\n",
        "\n",
        "Code base : https://github.com/xingyizhou/CenterNet\n",
        "\n",
        "Data : https://www.kaggle.com/competitions/pku-autonomous-driving/data\n",
        "\n",
        "Competitions : https://www.kaggle.com/code/hocop1/centernet-baseline/notebook#3D-Visualization\n",
        "\n",
        "Consize explanation here : https://www.youtube.com/watch?v=pDqoJNJfEZo\n",
        "One correction in this video is that centernet directly finds center of\n",
        "3D object rather to find first the center of 2D and then go to 3D.\n",
        "\n",
        "Authors explaining it : https://www.youtube.com/watch?v=9vM6E6zoA84 \n",
        "\n",
        "Untill now we learned yolo and centernet. Also read cascade R-CNN, that\n",
        "improves consists of a sequence of detectors trained end-to-end with increasing IoU thresholds, to be sequentially more selective against close false positives. The output of a previous stage detector is forwarded to a later stage detector, and the detection results will be improved stage by stage.\n",
        "But as u know inference time is problem with the R-CNN: \n",
        "\n",
        "https://arxiv.org/abs/1712.00726 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dZlkdlmoSVbI"
      },
      "outputs": [],
      "source": [
        "#@title installs and imports\n",
        "\n",
        "!pip install efficientnet-pytorch\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "# read this: https://pytorch.org/hub/nvidia_deeplearningexamples_efficientnet/\n",
        "# and this: https://ai.googleblog.com/2019/05/efficientnet-improving-accuracy-and.html\n",
        "# quick eplanation here : https://www.youtube.com/watch?v=XiLy_2clr6s\n",
        "# also read the paper: https://arxiv.org/abs/1905.11946  \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import cv2\n",
        "from tqdm import tqdm#_notebook as tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from functools import reduce\n",
        "import os\n",
        "from scipy.optimize import minimize\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "from math import sin, cos\n",
        "import gc\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "v_3Yhig2W7Uq"
      },
      "outputs": [],
      "source": [
        "#@title downloads\n",
        "\n",
        "#please note: you have to get your kaggle.json contining API key and upload it in colab files section\n",
        "# here is step by step explanation how to do that: \n",
        "# https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/\n",
        "!pip install -q kaggle  \n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/   # you may not need this copying the json file to newly created directory if you uploaded it already in that directory, obviously\n",
        "!kaggle competitions download -c pku-autonomous-driving\n",
        "\n",
        "!unzip /content/pku-autonomous-driving.zip\n",
        "# !rm /content/pku-autonomous-driving.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1BFpg8l9JfV"
      },
      "source": [
        "# Data handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDIN8A7mVcUd"
      },
      "outputs": [],
      "source": [
        "PATH = './'\n",
        "os.listdir(PATH)\n",
        "\n",
        "train = pd.read_csv(PATH + 'train.csv')\n",
        "test = pd.read_csv(PATH + 'sample_submission.csv')\n",
        "\n",
        "# From camera.zip\n",
        "camera_matrix = np.array([[2304.5479, 0,  1686.2379],\n",
        "                          [0, 2305.8757, 1354.9849],\n",
        "                          [0, 0, 1]], dtype=np.float32)\n",
        "camera_matrix_inv = np.linalg.inv(camera_matrix)\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "cellView": "form",
        "id": "q_A1XzYIVsub"
      },
      "outputs": [],
      "source": [
        "#@title helper functions\n",
        "\n",
        "def imread(path, fast_mode=False):\n",
        "    img = cv2.imread(path)\n",
        "    if not fast_mode and img is not None and len(img.shape) == 3:\n",
        "        img = np.array(img[:, :, ::-1])\n",
        "    return img\n",
        "\n",
        "def rotate(x, angle):\n",
        "    x = x + angle\n",
        "    x = x - (x + np.pi) // (2 * np.pi) * 2 * np.pi\n",
        "    return x\n",
        "\n",
        "def str2coords(s, names=['id', 'yaw', 'pitch', 'roll', 'x', 'y', 'z']):\n",
        "    '''\n",
        "    Input:\n",
        "        s: PredictionString (e.g. from train dataframe)\n",
        "        names: array of what to extract from the string\n",
        "    Output:\n",
        "        list of dicts with keys from `names`\n",
        "    '''\n",
        "    coords = []\n",
        "    for l in np.array(s.split()).reshape([-1, 7]):\n",
        "        coords.append(dict(zip(names, l.astype('float'))))\n",
        "        if 'id' in coords[-1]:\n",
        "            coords[-1]['id'] = int(coords[-1]['id'])\n",
        "    return coords\n",
        "\n",
        "def coords2str(coords, names=['yaw', 'pitch', 'roll', 'x', 'y', 'z', 'confidence']):\n",
        "    s = []\n",
        "    for c in coords:\n",
        "        for n in names:\n",
        "            s.append(str(c.get(n, 0)))\n",
        "    return ' '.join(s)\n",
        "    \n",
        "\n",
        "###----------------function for 2D visualizations start here--------------------\n",
        "\n",
        "def get_img_coords(s):\n",
        "    '''\n",
        "    Input is a PredictionString (e.g. from train dataframe)\n",
        "    Output is two arrays:\n",
        "        xs: x coordinates in the image (row)\n",
        "        ys: y coordinates in the image (column)\n",
        "    '''\n",
        "    coords = str2coords(s)\n",
        "    xs = [c['x'] for c in coords]\n",
        "    ys = [c['y'] for c in coords]\n",
        "    zs = [c['z'] for c in coords]\n",
        "    P = np.array(list(zip(xs, ys, zs))).T\n",
        "    img_p = np.dot(camera_matrix, P).T\n",
        "    img_p[:, 0] /= img_p[:, 2]\n",
        "    img_p[:, 1] /= img_p[:, 2]\n",
        "    img_xs = img_p[:, 0]\n",
        "    img_ys = img_p[:, 1]\n",
        "    img_zs = img_p[:, 2] # z = Distance from the camera\n",
        "    return img_xs, img_ys\n",
        "\n",
        "\n",
        "###--------------- functions for 3D visualizations stert here-------------------\n",
        "\n",
        "def draw_line(image, points):\n",
        "    color = (255, 0, 0)\n",
        "    cv2.line(image, tuple(points[0][:2]), tuple(points[3][:2]), color, 16)\n",
        "    cv2.line(image, tuple(points[0][:2]), tuple(points[1][:2]), color, 16)\n",
        "    cv2.line(image, tuple(points[1][:2]), tuple(points[2][:2]), color, 16)\n",
        "    cv2.line(image, tuple(points[2][:2]), tuple(points[3][:2]), color, 16)\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_points(image, points):\n",
        "    for (p_x, p_y, p_z) in points:\n",
        "        cv2.circle(image, (p_x, p_y), int(1000 / p_z), (0, 255, 0), -1)\n",
        "#         if p_x > image.shape[1] or p_y > image.shape[0]:\n",
        "#             print('Point', p_x, p_y, 'is out of image with shape', image.shape)\n",
        "    return image\n",
        "\n",
        "# convert euler angle to rotation matrix\n",
        "def euler_to_Rot(yaw, pitch, roll):\n",
        "    Y = np.array([[cos(yaw), 0, sin(yaw)],\n",
        "                  [0, 1, 0],\n",
        "                  [-sin(yaw), 0, cos(yaw)]])\n",
        "    P = np.array([[1, 0, 0],\n",
        "                  [0, cos(pitch), -sin(pitch)],\n",
        "                  [0, sin(pitch), cos(pitch)]])\n",
        "    R = np.array([[cos(roll), -sin(roll), 0],\n",
        "                  [sin(roll), cos(roll), 0],\n",
        "                  [0, 0, 1]])\n",
        "    return np.dot(Y, np.dot(P, R))\n",
        "\n",
        "def visualize(img, coords):\n",
        "    # You will also need functions from the previous cells\n",
        "    x_l = 1.02\n",
        "    y_l = 0.80\n",
        "    z_l = 2.31\n",
        "    \n",
        "    img = img.copy()\n",
        "    for point in coords:\n",
        "        # Get values\n",
        "        x, y, z = point['x'], point['y'], point['z']\n",
        "        yaw, pitch, roll = -point['pitch'], -point['yaw'], -point['roll']\n",
        "        # Math\n",
        "        Rt = np.eye(4)\n",
        "        t = np.array([x, y, z])\n",
        "        Rt[:3, 3] = t\n",
        "        Rt[:3, :3] = euler_to_Rot(yaw, pitch, roll).T\n",
        "        Rt = Rt[:3, :]\n",
        "        P = np.array([[x_l, -y_l, -z_l, 1],\n",
        "                      [x_l, -y_l, z_l, 1],\n",
        "                      [-x_l, -y_l, z_l, 1],\n",
        "                      [-x_l, -y_l, -z_l, 1],\n",
        "                      [0, 0, 0, 1]]).T\n",
        "        img_cor_points = np.dot(camera_matrix, np.dot(Rt, P))\n",
        "        img_cor_points = img_cor_points.T\n",
        "        img_cor_points[:, 0] /= img_cor_points[:, 2]\n",
        "        img_cor_points[:, 1] /= img_cor_points[:, 2]\n",
        "        img_cor_points = img_cor_points.astype(int)\n",
        "        # Drawing\n",
        "        img = draw_line(img, img_cor_points)\n",
        "        img = draw_points(img, img_cor_points[-1:])\n",
        "    \n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MwD0XlFqZVss"
      },
      "outputs": [],
      "source": [
        "#@title from 3D info to 2D image masks (prepare for regression) and image preprocessing\n",
        "\n",
        "\n",
        "IMG_WIDTH = 1024\n",
        "IMG_HEIGHT = IMG_WIDTH // 16 * 5\n",
        "MODEL_SCALE = 8\n",
        "\n",
        "def _regr_preprocess(regr_dict, flip=False):\n",
        "    if flip:\n",
        "        for k in ['x', 'pitch', 'roll']:\n",
        "            regr_dict[k] = -regr_dict[k]\n",
        "    for name in ['x', 'y', 'z']:\n",
        "        regr_dict[name] = regr_dict[name] / 100\n",
        "    regr_dict['roll'] = rotate(regr_dict['roll'], np.pi)\n",
        "    regr_dict['pitch_sin'] = sin(regr_dict['pitch'])\n",
        "    regr_dict['pitch_cos'] = cos(regr_dict['pitch'])\n",
        "    regr_dict.pop('pitch') # gives poped element with key 'pich'\n",
        "    regr_dict.pop('id')\n",
        "    return regr_dict\n",
        "\n",
        "def _regr_back(regr_dict):\n",
        "    for name in ['x', 'y', 'z']:\n",
        "        regr_dict[name] = regr_dict[name] * 100\n",
        "    regr_dict['roll'] = rotate(regr_dict['roll'], -np.pi)\n",
        "    \n",
        "    pitch_sin = regr_dict['pitch_sin'] / np.sqrt(regr_dict['pitch_sin']**2 + regr_dict['pitch_cos']**2)\n",
        "    pitch_cos = regr_dict['pitch_cos'] / np.sqrt(regr_dict['pitch_sin']**2 + regr_dict['pitch_cos']**2)\n",
        "    regr_dict['pitch'] = np.arccos(pitch_cos) * np.sign(pitch_sin)\n",
        "    return regr_dict\n",
        "\n",
        "\n",
        "def get_mask_and_regr(img, labels, flip=False):\n",
        "    mask = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE], dtype='float32')\n",
        "    regr_names = ['x', 'y', 'z', 'yaw', 'pitch', 'roll']\n",
        "    regr = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE, 7], dtype='float32')\n",
        "    coords = str2coords(labels)\n",
        "    xs, ys = get_img_coords(labels)\n",
        "    for x, y, regr_dict in zip(xs, ys, coords):\n",
        "        x, y = y, x\n",
        "        x = (x - img.shape[0] // 2) * IMG_HEIGHT / (img.shape[0] // 2) / MODEL_SCALE\n",
        "        x = np.round(x).astype('int')\n",
        "        y = (y + img.shape[1] // 6) * IMG_WIDTH / (img.shape[1] * 4/3) / MODEL_SCALE\n",
        "        y = np.round(y).astype('int')\n",
        "        if x >= 0 and x < IMG_HEIGHT // MODEL_SCALE and y >= 0 and y < IMG_WIDTH // MODEL_SCALE:\n",
        "            mask[x, y] = 1\n",
        "            regr_dict = _regr_preprocess(regr_dict, flip)\n",
        "            regr[x, y] = [regr_dict[n] for n in sorted(regr_dict)]\n",
        "    if flip:\n",
        "        mask = np.array(mask[:,::-1])\n",
        "        regr = np.array(regr[:,::-1])\n",
        "    return mask, regr\n",
        "\n",
        "def preprocess_image(img, flip=False):\n",
        "    img = img[img.shape[0] // 2:]\n",
        "    bg = np.ones_like(img) * img.mean(1, keepdims=True).astype(img.dtype)\n",
        "    bg = bg[:, :img.shape[1] // 6]\n",
        "    img = np.concatenate([bg, img, bg], 1)\n",
        "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "    if flip:\n",
        "        img = img[:,::-1]\n",
        "    return (img / 255).astype('float32')\n",
        "\n",
        "\n",
        "## check if image preprocessing works\n",
        "\n",
        "img0 = imread(PATH + 'train_images/' + train['ImageId'][6] + '.jpg')\n",
        "img = preprocess_image(img0)\n",
        "\n",
        "mask, regr = get_mask_and_regr(img0, train['PredictionString'][6])\n",
        "\n",
        "print('img.shape', img.shape, 'std:', np.std(img))\n",
        "print('mask.shape', mask.shape, 'std:', np.std(mask))\n",
        "print('regr.shape', regr.shape, 'std:', np.std(regr))\n",
        "\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.title('Processed image')\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.title('Detection Mask')\n",
        "plt.imshow(mask)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.title('Yaw values')\n",
        "plt.imshow(regr[:,:,-2])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "J2CcgpS5ZjvE"
      },
      "outputs": [],
      "source": [
        "#@title functions for converting from 2D to 3D \n",
        "\n",
        "### functions to convert back from 2d map to 3d coordinates and angles\n",
        "\n",
        "DISTANCE_THRESH_CLEAR = 2\n",
        "\n",
        "def convert_3d_to_2d(x, y, z, fx = 2304.5479, fy = 2305.8757, cx = 1686.2379, cy = 1354.9849):\n",
        "    # from https://www.kaggle.com/theshockwaverider/eda-visualization-baseline\n",
        "    return x * fx / z + cx, y * fy / z + cy\n",
        "\n",
        "def optimize_xy(r, c, x0, y0, z0, flipped=False):\n",
        "    def distance_fn(xyz):\n",
        "        x, y, z = xyz\n",
        "        xx = -x if flipped else x\n",
        "        slope_err = (xzy_slope.predict([[xx,z]])[0] - y)**2\n",
        "        x, y = convert_3d_to_2d(x, y, z)\n",
        "        y, x = x, y\n",
        "        x = (x - IMG_SHAPE[0] // 2) * IMG_HEIGHT / (IMG_SHAPE[0] // 2) / MODEL_SCALE\n",
        "        y = (y + IMG_SHAPE[1] // 6) * IMG_WIDTH / (IMG_SHAPE[1] * 4 / 3) / MODEL_SCALE\n",
        "        return max(0.2, (x-r)**2 + (y-c)**2) + max(0.4, slope_err)\n",
        "    \n",
        "    res = minimize(distance_fn, [x0, y0, z0], method='Powell')\n",
        "    x_new, y_new, z_new = res.x\n",
        "    return x_new, y_new, z_new\n",
        "\n",
        "def clear_duplicates(coords):\n",
        "    for c1 in coords:\n",
        "        xyz1 = np.array([c1['x'], c1['y'], c1['z']])\n",
        "        for c2 in coords:\n",
        "            xyz2 = np.array([c2['x'], c2['y'], c2['z']])\n",
        "            distance = np.sqrt(((xyz1 - xyz2)**2).sum())\n",
        "            if distance < DISTANCE_THRESH_CLEAR:\n",
        "                if c1['confidence'] < c2['confidence']:\n",
        "                    c1['confidence'] = -1\n",
        "    return [c for c in coords if c['confidence'] > 0]\n",
        "\n",
        "def extract_coords(prediction, flipped=False):\n",
        "    logits = prediction[0]\n",
        "    regr_output = prediction[1:]\n",
        "    points = np.argwhere(logits > 0)\n",
        "    col_names = sorted(['x', 'y', 'z', 'yaw', 'pitch_sin', 'pitch_cos', 'roll'])\n",
        "    coords = []\n",
        "    for r, c in points:\n",
        "        regr_dict = dict(zip(col_names, regr_output[:, r, c]))\n",
        "        coords.append(_regr_back(regr_dict))\n",
        "        coords[-1]['confidence'] = 1 / (1 + np.exp(-logits[r, c]))\n",
        "        coords[-1]['x'], coords[-1]['y'], coords[-1]['z'] = \\\n",
        "                optimize_xy(r, c,\n",
        "                            coords[-1]['x'],\n",
        "                            coords[-1]['y'],\n",
        "                            coords[-1]['z'], flipped)\n",
        "    coords = clear_duplicates(coords)\n",
        "    return coords\n",
        "\n",
        "\n",
        "##  to check if all works\n",
        "\n",
        "def visualize_2dto3d(start=0, end=2, step=1):\n",
        "  for idx in range(start, end, step):\n",
        "      fig, axes = plt.subplots(1, 2, figsize=(20,20))\n",
        "      \n",
        "      for ax_i in range(2):\n",
        "          img0 = imread(PATH + 'train_images/' + train['ImageId'].iloc[idx] + '.jpg')\n",
        "          if ax_i == 1:\n",
        "              img0 = img0[:,::-1]\n",
        "          img = preprocess_image(img0, ax_i==1)\n",
        "          mask, regr = get_mask_and_regr(img0, train['PredictionString'][idx], ax_i==1)\n",
        "          regr = np.rollaxis(regr, 2, 0)\n",
        "          coords = extract_coords(np.concatenate([mask[None], regr], 0), ax_i==1)\n",
        "          \n",
        "          axes[ax_i].set_title('Flip = {}'.format(ax_i==1))\n",
        "          axes[ax_i].imshow(visualize(img0, coords))\n",
        "      plt.show()\n",
        "\n",
        "visualize_2dto3d()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XY0nmXemZ-Tb"
      },
      "outputs": [],
      "source": [
        "#@title data handling\n",
        "\n",
        "class CarDataset(Dataset):\n",
        "    \"\"\"Car dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, dataframe, root_dir, training=True, transform=None):\n",
        "        self.df = dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.training = training\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        \n",
        "        # Get image name\n",
        "        idx, labels = self.df.values[idx]\n",
        "        img_name = self.root_dir.format(idx)\n",
        "        \n",
        "        # Augmentation\n",
        "        flip = False\n",
        "        if self.training:\n",
        "            flip = np.random.randint(10) == 1\n",
        "        \n",
        "        # Read image\n",
        "        img0 = imread(img_name, True)\n",
        "        img = preprocess_image(img0, flip=flip)\n",
        "        img = np.rollaxis(img, 2, 0)\n",
        "        \n",
        "        # Get mask and regression maps\n",
        "        mask, regr = get_mask_and_regr(img0, labels, flip=flip)\n",
        "        regr = np.rollaxis(regr, 2, 0)\n",
        "        \n",
        "        return [img, mask, regr]\n",
        "\n",
        "\n",
        "train_images_dir = PATH + 'train_images/{}.jpg'\n",
        "test_images_dir = PATH + 'test_images/{}.jpg'\n",
        "\n",
        "df_train, df_dev = train_test_split(train, test_size=0.01, random_state=42)\n",
        "df_test = test\n",
        "\n",
        "# Create dataset objects\n",
        "train_dataset = CarDataset(df_train, train_images_dir, training=True)\n",
        "dev_dataset = CarDataset(df_dev, train_images_dir, training=False)\n",
        "test_dataset = CarDataset(df_test, test_images_dir, training=False)\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "# Create data generators - they will produce batches\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "dev_loader = DataLoader(dataset=dev_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "## check if all works\n",
        "\n",
        "img, mask, regr = train_dataset[0]\n",
        "\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.imshow(np.rollaxis(img, 0, 3))\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.imshow(mask)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.imshow(regr[-2])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Ga0wa5aafd47",
        "0s60IvQm9V6N",
        "gJ2NFCvi9ajm"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
