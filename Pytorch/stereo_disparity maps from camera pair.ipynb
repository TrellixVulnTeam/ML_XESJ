{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MpQNPIuKNIM5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import listdir, path\n",
        "import sys\n",
        "from threading import Thread, Lock\n",
        "import time\n",
        "from imageio import imread, imwrite\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.signal import convolve\n",
        "from skimage.transform import rescale\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieuUjsU-NuO4"
      },
      "outputs": [],
      "source": [
        "# Lado download data given by Prof Geiger here :  https://1drv.ms/u/s!AhnVhbVlzYkKgQU3fIH8gby6yJ2E?e=0Kj2Td \n",
        "!unzip KITTI_2015_subset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "IONyCqj-Mtga"
      },
      "outputs": [],
      "source": [
        "#@title data handling { form-width: \"20%\" }\n",
        "\n",
        "#!/usr/bin/env python\n",
        "\"\"\"Dataloader for siamese training\n",
        "\"\"\"\n",
        "\n",
        "# convert rgb image to grayscale\n",
        "def rgb2gray(I):\n",
        "    return np.dot(I[...,:3], [0.299, 0.587, 0.114])\n",
        "\n",
        "\n",
        "class KITTIDataset(object):\n",
        "    def __init__(self, image_dir, disparity_dir=None, downsample=True):\n",
        "        self.disparity_dir = disparity_dir\n",
        "        self.downsample = downsample\n",
        "\n",
        "        left_dir = path.join(image_dir, \"image_2\")\n",
        "        right_dir = path.join(image_dir, \"image_3\")\n",
        "\n",
        "        self._left_images = sorted([\n",
        "            path.join(left_dir, img) for img in listdir(left_dir) if \"_10.\" in img\n",
        "        ])\n",
        "        self._right_images = sorted([\n",
        "            path.join(right_dir, img) for img in listdir(right_dir) if \"_10.\" in img\n",
        "        ])\n",
        "        assert len(self._left_images) == len(self._right_images)\n",
        "\n",
        "        if disparity_dir is not None:\n",
        "            self._disp_images = sorted([\n",
        "                path.join(disparity_dir, img) for img in listdir(disparity_dir)\n",
        "            ])\n",
        "            assert len(self._left_images) == len(self._disp_images)\n",
        "        else:\n",
        "            self._disp_images = []\n",
        "\n",
        "        print('KITTI data loaded (%d images)!' % len(self._left_images))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._left_images)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        img_l = imread(self._left_images[i]).astype(np.float32) / 255.\n",
        "        img_r = imread(self._right_images[i]).astype(np.float32) / 255.\n",
        "        \n",
        "        img_l = rgb2gray(img_l)[..., np.newaxis]\n",
        "        img_r = rgb2gray(img_r)[..., np.newaxis]\n",
        "\n",
        "        if self.downsample:\n",
        "            img_l = rescale(img_l, 0.5, mode='reflect', anti_aliasing=True, multichannel=True)\n",
        "            img_r = rescale(img_r, 0.5, mode='reflect', anti_aliasing=True, multichannel=True)\n",
        "\n",
        "        if self.disparity_dir is not None:\n",
        "            disp = imread(self._disp_images[i]).astype(np.float32) / 256.\n",
        "        \n",
        "            if self.downsample:\n",
        "                H, W = disp.shape\n",
        "                disp = disp[np.arange(0, H, 2), :] # Downsample first dimension\n",
        "                disp = disp[:, np.arange(0, W, 2)] # Downsample second dimension\n",
        "                disp = disp / 2. # Scale values accordingly\n",
        "\n",
        "            disp[disp <= 0] = -1\n",
        "    \n",
        "            return img_l, img_r, disp\n",
        "        else:\n",
        "            return img_l, img_r\n",
        "\n",
        "\n",
        "class PatchProvider(object):\n",
        "    \"\"\"Provide training patches\"\"\"\n",
        "    def __init__(self, data, patch_size=(7, 7), N=(4, 10), P=1):\n",
        "        self._data = data\n",
        "        self._patch_size = patch_size\n",
        "        self._N = N\n",
        "        self._P = P\n",
        "        self.idxs = None\n",
        "\n",
        "        self._stop = False\n",
        "        self._cache = 5\n",
        "        self._lock = Lock()\n",
        "\n",
        "\n",
        "    def _get_neg_idx(self, col, W):\n",
        "        # local copy for convenience\n",
        "        half_patch = self._patch_size[1]//2\n",
        "        N = self._N\n",
        "\n",
        "        neg_offset = np.random.randint(N[0], N[1] + 1)\n",
        "        neg_offset = neg_offset * np.sign(np.random.rand() - 0.5).astype(np.int32)\n",
        "\n",
        "        if half_patch <= col + neg_offset < W-half_patch:\n",
        "            return slice(col+neg_offset-half_patch, col+neg_offset+half_patch+1)\n",
        "        else:\n",
        "            return self._get_neg_idx(col, W)\n",
        "\n",
        "    def _get_pos_idx(self, col, W):\n",
        "        # local copy for convenience\n",
        "        half_patch = self._patch_size[1]//2\n",
        "        P = self._P\n",
        "\n",
        "        pos_offset = np.random.randint(-P, P+1)\n",
        "        if half_patch <= col + pos_offset < W-half_patch:\n",
        "            return slice(col+pos_offset-half_patch, col+pos_offset+half_patch+1)\n",
        "        else:\n",
        "            return self._get_pos_idx(col, W)\n",
        "        \n",
        "    def random_patch(self):\n",
        "        # local copy for convenience\n",
        "        patch_size = self._patch_size\n",
        "        half_patch = np.array(patch_size)//2\n",
        "        img_l, img_r, disp = self._data[int(np.random.rand()*len(self._data))]\n",
        "        H, W = img_l.shape[:2]\n",
        "        while True:\n",
        "            half_p = patch_size[0] // 2\n",
        "            row = np.random.randint(half_p, H - half_p)\n",
        "            col = np.random.randint(half_p, W - half_p)\n",
        "            d = disp[row, col]\n",
        "            if d > 0 and (col - d) > half_p and (col - d) < W - half_p:\n",
        "                break\n",
        "\n",
        "        ref_idx = (\n",
        "            slice(row-half_patch[0], row+half_patch[0]+1),\n",
        "            slice(col-half_patch[1], col+half_patch[1]+1)\n",
        "        )\n",
        "        neg_idx = (\n",
        "            slice(row-half_patch[0], row+half_patch[0]+1),\n",
        "            self._get_neg_idx(int(col - disp[row, col]), W)\n",
        "        )\n",
        "        pos_idx = (\n",
        "            slice(row-half_patch[0], row+half_patch[0]+1),\n",
        "            self._get_pos_idx(int(col - disp[row, col]), W)\n",
        "        )\n",
        "        return img_l[ref_idx], img_r[pos_idx], img_r[neg_idx]\n",
        "        #return img_l[ref_idx], img_r[pos_idx], np.random.random(patch_size + (3,))\n",
        "\n",
        "    def iterate_batches(self, batch_size):\n",
        "        # Get a patch to infer the image shape\n",
        "\n",
        "        patch = self.random_patch()\n",
        "        channels = patch[0].shape[-1]\n",
        "\n",
        "        ref_batch = np.zeros(\n",
        "            (self._cache*batch_size, ) + self._patch_size + (channels,),\n",
        "            dtype=\"float32\"\n",
        "        )\n",
        "        pos_batch = np.zeros_like(ref_batch)\n",
        "        neg_batch = np.zeros_like(ref_batch)\n",
        "\n",
        "        # start the thread\n",
        "        self._thread = Thread(\n",
        "            target=self.fill_batches,\n",
        "            args=(ref_batch, pos_batch, neg_batch)\n",
        "        )\n",
        "        self._stop = False\n",
        "        self._thread.start()\n",
        "\n",
        "        # wait for the buffers to fill\n",
        "        while True:\n",
        "            time.sleep(1)\n",
        "            with self._lock:\n",
        "                if ref_batch[-1].sum() == 0:\n",
        "                    pass\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "        # start generating batches\n",
        "        while True:\n",
        "            self.idxs = np.random.choice(len(ref_batch), batch_size)\n",
        "            with self._lock:\n",
        "                yield torch.Tensor(ref_batch[self.idxs]).cuda(), \\\n",
        "                      torch.Tensor(pos_batch[self.idxs]).cuda(), \\\n",
        "                      torch.Tensor(neg_batch[self.idxs]).cuda()\n",
        "\n",
        "    def fill_batches(self, ref, pos, neg):\n",
        "        idx = 0\n",
        "        while not self._stop:\n",
        "            patch = self.random_patch()\n",
        "            with self._lock:\n",
        "                ref[idx] = patch[0]\n",
        "                pos[idx] = patch[1]\n",
        "                neg[idx] = patch[2]\n",
        "            idx += 1\n",
        "            idx = idx % len(ref)\n",
        "\n",
        "    def stop(self):\n",
        "        self._stop = True\n",
        "        self._thread.join()\n",
        "\n",
        "def upsample_disparity_map(disparity_map, output_shape, sampling_factor=2.):\n",
        "    ''' Upsamples the disparity map to the provided output shape.\n",
        "\n",
        "    Please note that when upsampling the disparity, the value need to be adjusted\n",
        "    with regard to the downsampling factor of the images for which the disparity\n",
        "    was calculated. For example, when we half the resolution before calculating\n",
        "    the disparity, we need to multiply the disparity by 2 if we want to obtain\n",
        "    the disparity map for the original size. \n",
        "    \n",
        "    Arguments:\n",
        "    ----------\n",
        "        disparity_map: disparity map \n",
        "        output_shape: desired output shape\n",
        "        sampling_factor: sampling factor by which the upsampled disparity map is\n",
        "            multiplied (default: 2.)\n",
        "    '''\n",
        "    #disparity_map = imresize(disparity_map, output_shape, interp='nearest')\n",
        "    disparity_map = disparity_map * sampling_factor\n",
        "    return disparity_map\n",
        "\n",
        "\n",
        "def return_accuracy(pred_disparity, gt_disparity, threshold=1.5):\n",
        "    \"\"\" Returns the accuracy for the predicted and GT disparity maps.\n",
        "\n",
        "    Arguments:\n",
        "    ----------\n",
        "        pred_disparity: predicted disparity map \n",
        "        gt_disparity: ground truth disparity map \n",
        "        threshold: threshold value defining which maximum difference should be considered correct (default 3)\n",
        "        half_resolution: whether the disparity was calculated on half resolution images. If so, the predicted \n",
        "            disparity map needs to be upsampled and multiplied by 2 before comparing against the ground truth\n",
        "    \"\"\"\n",
        "\n",
        "    diff = np.abs(pred_disparity - gt_disparity)\n",
        "    mask = gt_disparity > 0.\n",
        "\n",
        "    diff[mask == 0] = 0.\n",
        "\n",
        "    correct = (np.abs(gt_disparity[mask] - pred_disparity[mask]) < threshold).sum()\n",
        "    total = mask.sum()    \n",
        "    acc = correct / total\n",
        "\n",
        "    return diff, acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "z3cVriwnLEwy",
        "outputId": "a1c89895-de1c-463f-bb77-514cd000b6d3"
      },
      "outputs": [],
      "source": [
        "input_dir = './KITTI_2015_subset'\n",
        "window_size = 3\n",
        "max_disparity = 50\n",
        "out_dir = os.path.join(\n",
        "    './output/handcrafted_stereo', 'window_size_%d' % window_size\n",
        ")\n",
        "\n",
        "# Create output directory\n",
        "if not os.path.isdir(out_dir):\n",
        "    os.makedirs(out_dir)\n",
        "    \n",
        "# Load dataset\n",
        "dset = KITTIDataset(os.path.join(input_dir, \"data_scene_flow/testing/\"))\n",
        "\n",
        "fig = plt.figure(figsize=(15,10))\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax1.imshow(dset[0][0].squeeze(), cmap='gray')\n",
        "ax1.title.set_text('Left Image')\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.imshow(dset[0][1].squeeze(), cmap='gray')\n",
        "ax2.title.set_text('Right Image')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WODO3Dd4tF_7"
      },
      "source": [
        "block matching algorithm implementation just to compare its results with siamese net results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "dbCynr2_LEw2"
      },
      "outputs": [],
      "source": [
        "def add_padding(I, padding):\n",
        "    \"\"\"\n",
        "    Adds zero padding to an RGB or grayscale image.\n",
        "\n",
        "    Args:\n",
        "        I (np.ndarray): HxWx? numpy array containing RGB or grayscale image\n",
        "    \n",
        "    Returns:\n",
        "        P (np.ndarray): (H+2*padding)x(W+2*padding)x? numpy array containing zero padded image\n",
        "    \"\"\"\n",
        "    if len(I.shape) == 2:\n",
        "        H, W = I.shape\n",
        "        padded = np.zeros((H+2*padding, W+2*padding), dtype=np.float32)\n",
        "        padded[padding:-padding, padding:-padding] = I\n",
        "    else:\n",
        "        H, W, C = I.shape\n",
        "        padded = np.zeros((H+2*padding, W+2*padding, C), dtype=I.dtype)\n",
        "        padded[padding:-padding, padding:-padding] = I\n",
        "\n",
        "    return padded\n",
        "\n",
        "\n",
        "def sad(image_left, image_right, window_size=3, max_disparity=50):\n",
        "    \"\"\"\n",
        "    Compute the sum of absolute differences between image_left and image_right.\n",
        "\n",
        "    Args:\n",
        "        image_left (np.ndarray): HxW numpy array containing grayscale right image\n",
        "        image_right (np.ndarray): HxW numpy array containing grayscale left image\n",
        "        window_size: window size (default 3)\n",
        "        max_disparity: maximal disparity to reduce search range (default 50)\n",
        "    \n",
        "    Returns:\n",
        "        D (np.ndarray): HxW numpy array containing the disparity for each pixel\n",
        "    \"\"\"\n",
        "\n",
        "    D = np.zeros_like(image_left)\n",
        "\n",
        "    # add zero padding\n",
        "    padding = window_size // 2\n",
        "    image_left = add_padding(image_left, padding).astype(np.float32)\n",
        "    image_right = add_padding(image_right, padding).astype(np.float32)\n",
        "    \n",
        "    height = image_left.shape[0]\n",
        "    width = image_left.shape[1]\n",
        "\n",
        "    # for each row\n",
        "    for h in range(height - window_size + 1):        \n",
        "        # for each column\n",
        "        for w in range(width - window_size + 1):\n",
        "            # set cost for each column to infinity\n",
        "            cost = np.ones(max_disparity+1) * np.inf\n",
        "            \n",
        "            # for each disparity [0, max_disparity]\n",
        "            for d in range(0, max_disparity+1):\n",
        "                # get column shifted by disparity d\n",
        "                shifted = w - d\n",
        "                \n",
        "                # check validity\n",
        "                if shifted < 0:\n",
        "                    continue\n",
        "\n",
        "                # extract patch image_left\n",
        "                patch_image_left = image_left[h:h+window_size, w:w+window_size]\n",
        "                \n",
        "                # extract patch image_right shifted by disparity d (shifted)\n",
        "                patch_image_right = image_right[h:h+window_size, shifted:shifted+window_size]\n",
        "                \n",
        "                # compute absolute difference\n",
        "                sad = np.sum(np.abs(patch_image_left - patch_image_right))\n",
        "\n",
        "                # sum absolute difference                \n",
        "                cost[d] = sad\n",
        "                # -------------------------------------    \n",
        "            # find the minimum cost\n",
        "            D[h, w] = np.argmin(cost)\n",
        "    return D\n",
        "\n",
        "\n",
        "def sad_convolve(image_left, image_right, window_size=3, max_disparity=50):\n",
        "    \"\"\"\n",
        "    Compute the sum of absolute differences between image_left and image_right\n",
        "    by using a mean filter.\n",
        "\n",
        "    Args:\n",
        "        image_left (np.nfarray): HxW numpy array containing grayscale right image\n",
        "        image_right (np.nfarray): HxW numpy array containing grayscale left image\n",
        "        window_size: window size (default 3)\n",
        "        max_disparity: maximal disparity to reduce search range (default 50)\n",
        "    \n",
        "    Returns:\n",
        "        D (np.ndarray): HxW numpy array containing the disparity for each pixel\n",
        "    \"\"\"\n",
        "\n",
        "    h, w = image_left.shape\n",
        "\n",
        "    kernel = np.ones((window_size, window_size)) / (window_size ** 2)\n",
        "\n",
        "    sad = np.zeros((h, w, max_disparity + 1))\n",
        "    img_r = image_right\n",
        "    for d in range(max_disparity + 1):\n",
        "        # Slide right image to the right\n",
        "        if d > 0:\n",
        "            img_r = np.zeros_like(image_right)\n",
        "            img_r[:, d:] = image_right[:, :-d]\n",
        "        \n",
        "        # Calculate difference image and convolve\n",
        "        img_difference = np.abs(image_left - img_r)\n",
        "        img_response = convolve(img_difference, kernel, mode='same', method='direct')\n",
        "\n",
        "        sad[:, :, d] = img_response\n",
        "\n",
        "    # Find argmins which are disparity values\n",
        "    D = np.argmin(sad, axis=2)\n",
        "    return D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "yTFJm_lNLEw6"
      },
      "outputs": [],
      "source": [
        "def visualize_disparity(disparity, im_left, im_right, title='Disparity Map', max_disparity=50):\n",
        "    \"\"\"\n",
        "    Generates a visualization for the disparity map.\n",
        "\n",
        "    Args:\n",
        "        disparity (np.array): disparity map\n",
        "        title: plot title\n",
        "        out_file: output file path\n",
        "        max_disparity: maximum disparity\n",
        "    \"\"\"\n",
        "\n",
        "    # visualize stereo pair\n",
        "    fig = plt.figure(figsize=(15, 5))\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    ax1 = fig.add_subplot(211)\n",
        "    ax1.imshow(im_left, cmap='gray')\n",
        "    \n",
        "    # visualize disparity\n",
        "    ax2 = fig.add_subplot(212)\n",
        "    im = ax2.imshow(disparity, cmap='Spectral', vmin=0, vmax=max_disparity)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16UURAkMLEw8"
      },
      "outputs": [],
      "source": [
        "for i in range(len(dset)):\n",
        "        # Load left and right images\n",
        "        im_left, im_right  = dset[i]\n",
        "        im_left, im_right = im_left.squeeze(-1), im_right.squeeze(-1)\n",
        "\n",
        "        # Calculate disparity\n",
        "        D = sad(im_left, im_right, window_size=window_size, max_disparity=max_disparity)\n",
        "\n",
        "        # Define title for the plot\n",
        "        title = 'Disparity map for image %04d with block matching (window size %d)' % (i, window_size)\n",
        "        # Define output file name and patch\n",
        "        file_name = '%04d_w%03d.png' % (i, window_size)\n",
        "        out_file_path = os.path.join(out_dir, file_name)\n",
        "\n",
        "        # Visualize the disparty and save it to a file\n",
        "        visualize_disparity(D, im_left, im_right, title=title, max_disparity=max_disparity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXRogBwOtpG6"
      },
      "source": [
        "Siamese Network implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIfBR25eLEw_"
      },
      "outputs": [],
      "source": [
        "class StereoMatchingNetwork(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Implementation of the network layers.\n",
        "        Layer output tensor size: (batch_size, n_features, height - 8, width - 8)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        gpu = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "        hidden_size = 64\n",
        "        self.conv_layers = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels=1, out_channels=hidden_size, kernel_size=3),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(in_channels=hidden_size, out_channels=hidden_size, kernel_size=3),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(in_channels=hidden_size, out_channels=hidden_size, kernel_size=3),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(in_channels=hidden_size, out_channels=hidden_size, kernel_size=3)\n",
        "        ).to(gpu)\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\" \n",
        "        The forward pass of the network. Returns the features for a given image patch.\n",
        "\n",
        "        Args:\n",
        "            X (torch.Tensor): image patch of shape (batch_size, height, width, n_channels)\n",
        "\n",
        "        Returns:\n",
        "            features (torch.Tensor): predicted normalized features of the input image patch X,\n",
        "                               shape (batch_size, height - 8, width - 8, n_features)\n",
        "        \"\"\"\n",
        "\n",
        "        X = X.permute(0, 3, 1, 2)\n",
        "        X = self.conv_layers(X)\n",
        "        features = torch.nn.functional.normalize(X, dim=1, p=2)\n",
        "        return features.permute(0, 2, 3, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZI4UalRLExA"
      },
      "outputs": [],
      "source": [
        "def calculate_similarity_score(infer_similarity_metric, Xl, Xr):\n",
        "    \"\"\"\n",
        "    Computes the similarity score for two stereo image patches.\n",
        "\n",
        "    Args:\n",
        "        infer_similarity_metric (torch.nn.Module):  pytorch module object\n",
        "        Xl (torch.Tensor): tensor holding the left image patch\n",
        "        Xr (torch.Tensor): tensor holding the right image patch\n",
        "\n",
        "    Returns:\n",
        "        score (torch.Tensor): the similarity score of both image patches which is the dot product of their features\n",
        "    \"\"\"\n",
        "\n",
        "    # run the forward pass of the network for both images\n",
        "    Fl = infer_similarity_metric(Xl)\n",
        "    Fr = infer_similarity_metric(Xr)\n",
        "    # the similarity score is the dot product of both feature tensors\n",
        "    return torch.sum(Fl * Fr, dim=-1).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkyI94uBLExB"
      },
      "outputs": [],
      "source": [
        "def hinge_loss(score_pos, score_neg, label):\n",
        "    \"\"\"\n",
        "    Computes the hinge loss for the similarity of a positive and a negative example.\n",
        "\n",
        "    Args:\n",
        "        score_pos (torch.Tensor): similarity score of the positive example\n",
        "        score_neg (torch.Tensor): similarity score of the negative example\n",
        "        label (torch.Tensor): the true labels\n",
        "\n",
        "    Returns:\n",
        "        avg_loss (torch.Tensor): the mean loss over the patch and the mini batch\n",
        "        acc (torch.Tensor): the accuracy of the prediction\n",
        "    \"\"\"\n",
        "    # Calculate the hinge loss max(0, margin + s_neg - s_pos)\n",
        "    loss = torch.max(0.2 + score_neg - score_pos, torch.zeros_like(score_pos))\n",
        "\n",
        "    # Obtain the mean over the patch and the mini batch\n",
        "    avg_loss = torch.mean(loss)\n",
        "\n",
        "    # Calculate the accuracy\n",
        "    similarity = torch.stack([score_pos, score_neg], dim=1)\n",
        "    labels = torch.argmax(label, dim=1)\n",
        "    predictions = torch.argmax(similarity, dim=1)\n",
        "    acc = torch.mean((labels == predictions).float())\n",
        "\n",
        "    return avg_loss, acc\n",
        "\n",
        "\n",
        "def training_loop(infer_similarity_metric, patches, optimizer, iterations=1000, batch_size=128):\n",
        "    '''\n",
        "    Runs the training loop of the siamese network.\n",
        "    \n",
        "    Args:\n",
        "        infer_similarity_metric (obj): pytorch module\n",
        "        patches (obj): patch provider object\n",
        "        optimizer (obj): optimizer object\n",
        "        iterations (int): number of iterations to perform\n",
        "        batch_size (int): batch size\n",
        "    '''\n",
        "\n",
        "    loss_list = []\n",
        "    try:\n",
        "        print(\"Starting training loop.\")\n",
        "        for idx, batch in zip(range(iterations), patches.iterate_batches(batch_size)):\n",
        "            # Extract the batches and labels\n",
        "            Xl, Xr_pos, Xr_neg = batch\n",
        "            # uncomment if you don't have a gpu\n",
        "            # Xl, Xr_pos, Xr_neg = Xl.cpu(), Xr_pos.cpu(), Xr_neg.cpu()\n",
        "            \n",
        "            # use this line if you have a gpu\n",
        "            label = torch.eye(2).cuda()[[0]*len(Xl)]  # label is always [1, 0]\n",
        "            # use this line if you don't have a gpu\n",
        "            # label = torch.eye(2)[[0]*len(Xl)]  # label is always [1, 0]\n",
        "\n",
        "            # calculate the similarity score\n",
        "            score_pos = calculate_similarity_score(infer_similarity_metric, Xl, Xr_pos)\n",
        "            score_neg = calculate_similarity_score(infer_similarity_metric, Xl, Xr_neg)\n",
        "            # compute the loss and accuracy\n",
        "            loss, acc = hinge_loss(score_pos, score_neg, label)\n",
        "\n",
        "            # compute the gradients\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # let the optimizer perform one step and update the weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # Append loss to list\n",
        "            loss_list.append(loss.item())\n",
        "\n",
        "            if idx % 50 == 0:\n",
        "                print(\"Loss (%04d it):%.04f \\tAccuracy: %0.3f\" % (idx, loss, acc))\n",
        "    finally:\n",
        "        patches.stop()\n",
        "        print(\"Finished training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7Ajs5prLExC",
        "outputId": "15bcd257-2fe5-4a6a-acca-4be29116b2ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KITTI data loaded (30 images)!\n",
            "Starting training loop.\n",
            "Loss (0000 it):0.1852 \tAccuracy: 0.828\n",
            "Loss (0050 it):0.1806 \tAccuracy: 0.844\n",
            "Loss (0100 it):0.1643 \tAccuracy: 0.812\n",
            "Loss (0150 it):0.1262 \tAccuracy: 0.859\n",
            "Loss (0200 it):0.1084 \tAccuracy: 0.867\n",
            "Loss (0250 it):0.1007 \tAccuracy: 0.836\n",
            "Loss (0300 it):0.0861 \tAccuracy: 0.875\n",
            "Loss (0350 it):0.0548 \tAccuracy: 0.922\n",
            "Loss (0400 it):0.0727 \tAccuracy: 0.867\n",
            "Loss (0450 it):0.0668 \tAccuracy: 0.914\n",
            "Loss (0500 it):0.0628 \tAccuracy: 0.922\n",
            "Loss (0550 it):0.0578 \tAccuracy: 0.922\n",
            "Loss (0600 it):0.0612 \tAccuracy: 0.945\n",
            "Loss (0650 it):0.0438 \tAccuracy: 0.953\n",
            "Loss (0700 it):0.0513 \tAccuracy: 0.922\n",
            "Loss (0750 it):0.0437 \tAccuracy: 0.969\n",
            "Loss (0800 it):0.0468 \tAccuracy: 0.945\n",
            "Loss (0850 it):0.0404 \tAccuracy: 0.961\n",
            "Loss (0900 it):0.0612 \tAccuracy: 0.914\n",
            "Loss (0950 it):0.0403 \tAccuracy: 0.945\n",
            "Finished training!\n"
          ]
        }
      ],
      "source": [
        "# Fix random seed for reproducibility        \n",
        "np.random.seed(7)\n",
        "torch.manual_seed(7)\n",
        "\n",
        "# Shortcuts for directories\n",
        "model_out_dir = os.path.join(out_dir, 'model')\n",
        "model_file = os.path.join(model_out_dir, \"model.t7\")\n",
        "\n",
        "# Hyperparameters\n",
        "training_iterations = 1000\n",
        "batch_size= 128\n",
        "learning_rate = 3e-4\n",
        "patch_size = 9\n",
        "padding = patch_size // 2\n",
        "max_disparity = 50\n",
        "\n",
        "# Check if output directory exists and if not create it\n",
        "if not os.path.exists(out_dir):\n",
        "    os.makedirs(out_dir)\n",
        "if not os.path.exists(model_out_dir):\n",
        "    os.makedirs(model_out_dir)\n",
        "\n",
        "# Create dataloader for KITTI training set\n",
        "dataset = KITTIDataset(\n",
        "    os.path.join(input_dir, \"data_scene_flow/training/\"),\n",
        "    os.path.join(input_dir, \"data_scene_flow/training/disp_noc_0\"),\n",
        ")\n",
        "# Load patch provider\n",
        "patches = PatchProvider(dataset, patch_size=(patch_size, patch_size))\n",
        "\n",
        "# Initialize the network\n",
        "infer_similarity_metric = StereoMatchingNetwork()\n",
        "# Set to train\n",
        "infer_similarity_metric.train()\n",
        "# uncomment if you don't have a gpu\n",
        "# infer_similarity_metric.to('cpu')\n",
        "optimizer = torch.optim.SGD(infer_similarity_metric.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "# Start training loop\n",
        "training_loop(infer_similarity_metric, patches, optimizer,\n",
        "                iterations=1000, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWgaZutiLExD"
      },
      "outputs": [],
      "source": [
        "def compute_disparity_CNN(infer_similarity_metric, img_l, img_r, max_disparity=50):\n",
        "    \"\"\"\n",
        "    Computes the disparity of the stereo image pair.\n",
        "\n",
        "    Args:\n",
        "        infer_similarity_metric:  pytorch module object\n",
        "        img_l: tensor holding the left image\n",
        "        img_r: tensor holding the right image\n",
        "        max_disparity (int): maximum disparity\n",
        "\n",
        "    Returns:\n",
        "        D: tensor holding the disparity\n",
        "    \"\"\"\n",
        "    # get the image features by applying the similarity metric\n",
        "    Fl = infer_similarity_metric(img_l[None])\n",
        "    Fr = infer_similarity_metric(img_r[None])\n",
        "\n",
        "    # images of shape B x H x W x C\n",
        "    B, H, W, C = Fl.shape\n",
        "    # Initialize the disparity\n",
        "    disparity = torch.zeros((B, H, W)).int()\n",
        "    # Initialize current similarity to -infimum\n",
        "    current_similarity = torch.ones((B, H, W)) * -np.inf\n",
        "\n",
        "    # Loop over all possible disparity values\n",
        "    Fr_shifted = Fr\n",
        "    for d in range(max_disparity + 1):\n",
        "        if d > 0:\n",
        "            # initialize shifted right image\n",
        "            Fr_shifted = torch.zeros_like(Fr)\n",
        "            # insert values which are shifted to the right by d\n",
        "            Fr_shifted[:, :, d:] = Fr[:, :, :-d]\n",
        "\n",
        "        # Calculate similarities\n",
        "        sim_d = torch.sum(Fl * Fr_shifted, dim=3)\n",
        "        # Check where similarity for disparity d is better than current one\n",
        "        indices_pos = sim_d > current_similarity\n",
        "        # Enter new similarity values\n",
        "        current_similarity[indices_pos] = sim_d[indices_pos]\n",
        "        # Enter new disparity values\n",
        "        disparity[indices_pos] = d\n",
        "\n",
        "    return disparity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2MI45M9sVgz"
      },
      "source": [
        "use this to compare results from siamese nets and block matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Wc_BrfJLExE"
      },
      "outputs": [],
      "source": [
        "# Set network to eval mode\n",
        "infer_similarity_metric.eval()\n",
        "infer_similarity_metric.to('cpu')\n",
        "\n",
        "# Load KITTI test split\n",
        "dataset = KITTIDataset(os.path.join(input_dir, \"data_scene_flow/testing/\"))\n",
        "# Loop over test images\n",
        "for i in range(len(dataset)):\n",
        "    print('Processing %d image' % i)\n",
        "    # Load images and add padding\n",
        "    img_left, img_right = dataset[i]\n",
        "    img_left_padded, img_right_padded = add_padding(img_left, padding), add_padding(img_right, padding)\n",
        "    img_left_padded, img_right_padded = torch.Tensor(img_left_padded), torch.Tensor(img_right_padded)\n",
        "\n",
        "    disparity_map = compute_disparity_CNN(\n",
        "        infer_similarity_metric, img_left_padded, img_right_padded, max_disparity=max_disparity\n",
        "    )\n",
        "    # Define title for the plot\n",
        "    title = 'Disparity map for image %04d with SNN \\\n",
        "        (training iterations %d, batch size %d, patch_size %d)' % (i, training_iterations, batch_size, patch_size)\n",
        "    visualize_disparity(disparity_map.squeeze(), img_left.squeeze(), img_right.squeeze(), title, max_disparity=max_disparity)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
