{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxFyEdAeJxD8"
      },
      "source": [
        "Data :  https://www.manythings.org/anki/ \n",
        "\n",
        "REFERENCE: https://arxiv.org/abs/1409.3215\n",
        "\n",
        "https://github.com/astorfi/sequence-to-sequence-from-scratch \n",
        "\n",
        "https://github.com/pskrunner14/translator\n",
        "\n",
        "https://github.com/spro/practical-pytorch \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48qCoCRNmk5w",
        "outputId": "a1ba3ef8-fcdf-4d80-dca1-e82ca715ffa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  deu-eng.zip\n",
            "  inflating: deu.txt                 \n",
            "  inflating: _about.txt              \n",
            "['Go.\\tGeh.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)\\n']\n"
          ]
        }
      ],
      "source": [
        "!wget -q https://www.manythings.org/anki/deu-eng.zip\n",
        "!unzip deu-eng.zip\n",
        "!mkdir data\n",
        "!cp -r ./deu.txt ./data/\n",
        "!mv ./data/deu.txt ./data/eng-deu.txt    #rename to express better what actually is in file\n",
        "\n",
        "# !rm deu-eng.zip\n",
        "# import shutil\n",
        "# shutil.rmtree('./ita_eng')\n",
        "\n",
        "#just inspect what is in file. You need this because:\n",
        "#mainly files are too large and take a lot of time to be oppened\n",
        "\n",
        "with open('./data/eng-deu.txt') as f:\n",
        "    lines = [line for line in f]\n",
        "  \n",
        "print(lines[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RxZv3azYJxD6"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "import unicodedata\n",
        "from io import open\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjizzMqoJxD-",
        "outputId": "b4426b3c-7001-4104-aee5-1e57ed3df130"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 255817 sentence pairs\n",
            "Trimmed to 255817 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 16400\n",
            "deu 36316\n",
            "['it is very kind of you to help me .', 'es ist sehr nett von dir mir zu helfen .']\n"
          ]
        }
      ],
      "source": [
        "#@title helpers and dataset\n",
        "\n",
        "SOS_token = 0  #start of string sos\n",
        "EOS_token = 1  #end of string eos\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, and make all case independent\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "\n",
        "#split the file into lines, and then split lines into pairs\n",
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('./data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in [l.split('\\t')[0], l.split('\\t')[1]]] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "MAX_LENGTH = 100\n",
        "\n",
        "###------------------- This part is for simplicity. Do not do it for full scale language translation tasks-----------------\n",
        "\n",
        "# eng_prefixes = (\n",
        "#     \"i am \", \"i m \",\n",
        "#     \"he is\", \"he s \",\n",
        "#     \"she is\", \"she s \",\n",
        "#     \"you are\", \"you re \",\n",
        "#     \"we are\", \"we re \",\n",
        "#     \"they are\", \"they re \"\n",
        "# )\n",
        "\n",
        "\n",
        "# def filterPair(p):\n",
        "#     return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "#         len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "#         p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "# def filterPairs(pairs):\n",
        "#     return [pair for pair in pairs if filterPair(pair)]\n",
        "###-------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse=False)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    # pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])  #these and followinf are Lang class methods that came here via readLangs\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "\n",
        "# class Dataset():\n",
        "#     \"\"\"dataset object\"\"\"\n",
        "\n",
        "#     def __init__(self, phase, num_embeddings=None, max_input_length=None, transform=None, auto_encoder=False):\n",
        "#         \"\"\"\n",
        "#         The initialization of the dataset object.\n",
        "#         :param phase: train/test.\n",
        "#         :param num_embeddings: The embedding dimentionality.\n",
        "#         :param max_input_length: The maximum enforced length of the sentences.\n",
        "#         :param transform: Post processing if necessary.\n",
        "#         :param auto_encoder: If we are training an autoencoder or not.\n",
        "#         \"\"\"\n",
        "#         if auto_encoder:\n",
        "#             lang_in = 'eng'\n",
        "#             lang_out = 'eng'\n",
        "#         else:\n",
        "#             lang_in = 'eng'\n",
        "#             lang_out = 'deu'\n",
        "#         # Skip and eliminate the sentences with a length larger than max_input_length!\n",
        "#         input_lang, output_lang, pairs = prepareData(lang_in, lang_out, max_input_length, auto_encoder=auto_encoder, reverse=True)\n",
        "#         print(random.choice(pairs))\n",
        "\n",
        "#         # Randomize list\n",
        "#         random.shuffle(pairs)\n",
        "\n",
        "#         if phase == 'train':\n",
        "#             selected_pairs = pairs[0:int(0.8 * len(pairs))]\n",
        "#         else:\n",
        "#             selected_pairs = pairs[int(0.8 * len(pairs)):]\n",
        "\n",
        "#         # Getting the tensors\n",
        "#         selected_pairs_tensors = [tensorsFromPair(selected_pairs[i], input_lang, output_lang, max_input_length)\n",
        "#                      for i in range(len(selected_pairs))]\n",
        "\n",
        "#         self.transform = transform\n",
        "#         self.num_embeddings = num_embeddings\n",
        "#         self.max_input_length = max_input_length\n",
        "#         self.data = selected_pairs_tensors\n",
        "#         self.input_lang = input_lang\n",
        "#         self.output_lang = output_lang\n",
        "\n",
        "#     def langs(self):\n",
        "#         return self.input_lang, self.output_lang\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "\n",
        "#         # A tuple which represent a pair\n",
        "#         pair = self.data[idx]\n",
        "\n",
        "#         # Define the sample dictionary\n",
        "#         sample = {'sentence': pair}\n",
        "\n",
        "#         if self.transform:\n",
        "#             sample = self.transform(sample)\n",
        "\n",
        "#         return sample\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'deu', True)\n",
        "print(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "920PXdWGJxEF"
      },
      "outputs": [],
      "source": [
        "#@title model\n",
        "\n",
        "### Encoder Part\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "# ### Simple RNN as Decoder \n",
        "# class DecoderRNN(nn.Module):\n",
        "#     def __init__(self, hidden_size, output_size):\n",
        "#         super(DecoderRNN, self).__init__()\n",
        "#         self.hidden_size = hidden_size\n",
        "\n",
        "#         self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "#         self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "#         self.out = nn.Linear(hidden_size, output_size)\n",
        "#         self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "#     def forward(self, input, hidden):\n",
        "#         output = self.embedding(input).view(1, 1, -1)\n",
        "#         output = F.relu(output)\n",
        "#         output, hidden = self.gru(output, hidden)\n",
        "#         output = self.softmax(self.out(output[0]))\n",
        "#         return output, hidden\n",
        "\n",
        "#     def initHidden(self):\n",
        "#         return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "\n",
        "### RNN with soft attention as Decoder\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxdIE3DCJxEK",
        "outputId": "51df9450-99df-4640-8d81-367eb3707f15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5000 6.666666666666667 5.02490188522883\n",
            "10000 13.333333333333334 4.558727198370314\n",
            "15000 20.0 4.244308231282164\n",
            "20000 26.666666666666668 4.026165815253845\n",
            "25000 33.33333333333333 3.8547518533637906\n",
            "30000 40.0 3.7505845219118448\n",
            "35000 46.666666666666664 3.619416537842642\n",
            "40000 53.333333333333336 3.503592566500375\n",
            "45000 60.0 3.458174200583728\n",
            "50000 66.66666666666666 3.397381521241445\n",
            "55000 73.33333333333333 3.345410415293697\n",
            "60000 80.0 3.317348715918124\n",
            "65000 86.66666666666667 3.254702951251409\n",
            "70000 93.33333333333333 3.1900487929929917\n",
            "75000 100.0 3.15929543934211\n"
          ]
        }
      ],
      "source": [
        "#@title training\n",
        "\n",
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n",
        "\n",
        "\n",
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    beta = float('inf')\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "\n",
        "        if loss<beta:\n",
        "          beta=loss\n",
        "          torch.save(encoder, './encoder_fullmodel.pth')\n",
        "          torch.save(decoder, './decoder_fullmodel.pth')\n",
        "          # torch.save(encoder.state_dict(), './encoder.pth')\n",
        "          # torch.save(decoder.state_dict(), './decoder.pth')\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print(iter, iter / n_iters * 100, print_loss_avg)\n",
        "\n",
        "hidden_size = 256\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder, attn_decoder, 75000, print_every=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5yW_jeTJxEM",
        "outputId": "57831e35-a704-4ca2-8d16-ebdfde8cf672"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> nobody loves you tom .\n",
            "= niemand liebt dich tom .\n",
            "< niemand liebt dich tom . <EOS>\n",
            "\n",
            "> does he go to school on foot or by bicycle ?\n",
            "= geht er zu fu zur schule oder fahrt er mit dem fahrrad ?\n",
            "< ist er mit dem mit zur schule zur schule oder ? <EOS>\n",
            "\n",
            "> she is both rich and very beautiful .\n",
            "= sie ist sowohl reich als auch sehr hubsch .\n",
            "< sie ist beide und und und ist . <EOS>\n",
            "\n",
            "> open it carefully .\n",
            "= offne es vorsichtig .\n",
            "< mach es ! <EOS>\n",
            "\n",
            "> give it a try .\n",
            "= versuch s doch mal !\n",
            "< versuchen es mal zu versuchen . <EOS>\n",
            "\n",
            "> what do you do with the rainwater you catch tom ?\n",
            "= was machst du mit dem aufgefangenen regenwasser tom ?\n",
            "< was ist du mit tom mit tom <EOS>\n",
            "\n",
            "> i am in the house .\n",
            "= ich bin in dem haus .\n",
            "< ich bin im haus . <EOS>\n",
            "\n",
            "> he represented the labor union on the committee .\n",
            "= er vertrat die arbeitergewerkschaft im komitee .\n",
            "< er setzte sich auf der . <EOS>\n",
            "\n",
            "> that s his business .\n",
            "= das ist seine sache .\n",
            "< das ist seine . . <EOS>\n",
            "\n",
            "> i agree with you .\n",
            "= ich bin deiner meinung .\n",
            "< ich stimme mit mir . <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title evaluation\n",
        "\n",
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]\n",
        "\n",
        "\n",
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')\n",
        "\n",
        "\n",
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(\n",
        "        encoder, attn_decoder, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "\n",
        "\n",
        "\n",
        "evaluateRandomly(encoder, attn_decoder)\n",
        "\n",
        "\n",
        "### DO NOT SAVE IN STATE DICT --> Save full model \n",
        "# torch.save(encoder.state_dict(), './encoder.pth')\n",
        "# torch.save(attn_decoder.state_dict(), './decoder.pth')\n",
        "# saved_encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "# saved_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "# saved_encoder.state_dict(torch.load('./encoder.pth'))\n",
        "# saved_decoder.state_dict(torch.load('./decoder.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-Y2KqbhKs8z"
      },
      "outputs": [],
      "source": [
        "# torch.save(encoder, './encoder_fullmodel.pth')\n",
        "# torch.save(attn_decoder, './decoder_fullmodel.pth')\n",
        "saved_encoder = torch.load('./encoder_fullmodel.pth').to(device)\n",
        "saved_decoder = torch.load('./decoder_fullmodel.pth').to(device)\n",
        "\n",
        "evaluateRandomly(saved_encoder, saved_decoder)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
