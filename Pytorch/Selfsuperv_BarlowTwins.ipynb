{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Read the article Barlow Twins - Self-Supervised Learning via Redundancy Reduction: https://arxiv.org/abs/2103.03230\n",
        "\n",
        "model architecture: https://www.researchgate.net/figure/Schematic-representation-of-Barlow-twinsZbontar-et-al-2021_fig1_362858330\n",
        "\n",
        "CIFAR-10 Dataset: https://www.cs.toronto.edu/~kriz/cifar.html "
      ],
      "metadata": {
        "id": "W4aqbYDCrj_T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r9CpnEyzQnbs"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models, transforms, datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IWx9znwp4x9"
      },
      "outputs": [],
      "source": [
        "train_set = datasets.CIFAR10(root='./data', train=True, download=True)\n",
        "val_set = datasets.CIFAR10(root='./data', train=False)\n",
        "print(f\"Total training examples: {len(train_set)}\")\n",
        "print(f\"Total validation examples: {len(val_set)}\")\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for n in range(25):\n",
        "    ax = plt.subplot(5, 5, n + 1)\n",
        "    plt.imshow(np.asarray(train_set[n][0]).astype(\"int\"))\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MuSihB2Ek3f3"
      },
      "outputs": [],
      "source": [
        "def get_transform():\n",
        "    '''\n",
        "    returns a transform that randomly crops, flips, jitters color or drops color from the input\n",
        "    '''\n",
        "    return transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, scale=[0.75, 1.0], \n",
        "                                            interpolation=Image.BICUBIC),\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.RandomApply(\n",
        "                    [transforms.ColorJitter(brightness=0.4, contrast=0.4,\n",
        "                                            saturation=0.2, hue=0.1)],\n",
        "                    p=0.9\n",
        "                ),\n",
        "                transforms.RandomGrayscale(p=0.3),\n",
        "            ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LVXbrial9_x"
      },
      "outputs": [],
      "source": [
        "t1 = get_transform()\n",
        "t2 = get_transform()\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "for n in range(8):\n",
        "    im_t1 = t1(train_set[n][0])\n",
        "    plt.subplot(2, 4, n + 1)\n",
        "    plt.imshow(np.asarray(im_t1).astype(\"int\"))\n",
        "    plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "for n in range(8):\n",
        "    im_t2 = t2(train_set[n][0])\n",
        "    plt.subplot(2, 4, n + 1)\n",
        "    plt.imshow(np.asarray(im_t2).astype(\"int\"))\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AuDx3hKJjiIv"
      },
      "outputs": [],
      "source": [
        "def off_diagonal(x):\n",
        "    '''\n",
        "    returns a flattened view of the off-diagonal elements of a square matrix x\n",
        "    '''\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    \n",
        "    def flatten(t):\n",
        "        return t.reshape(t.shape[0], -1)\n",
        "\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YFDyJZTijiIw"
      },
      "outputs": [],
      "source": [
        "def barlow_loss(z1, z2, bn, lambd):\n",
        "    '''\n",
        "    return the barlow twins loss function for a pair of features. Makes use of the off_diagonal function.\n",
        "    \n",
        "    :param z1: first input feature\n",
        "    :param z2: second input feature\n",
        "    :param bn: nn.BatchNorm1d layer applied to z1 and z2\n",
        "    :param lambd: trade-off hyper-parameter lambda\n",
        "    '''\n",
        "    # empirical cross-correlation matrix\n",
        "    c = torch.mm(bn(z1).T, bn(z2))\n",
        "    c.div_(z1.shape[0])\n",
        "\n",
        "    on_diag = torch.diagonal(c).add_(-1).pow_(2).sum()\n",
        "    off_diag = off_diagonal(c).pow_(2).sum()\n",
        "    return (on_diag + lambd * off_diag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZQownR3ajiIx"
      },
      "outputs": [],
      "source": [
        "class Projector(nn.Module):\n",
        "    '''\n",
        "    2-layer neural network (512 -> 256), (256 -> 128), ReLU non-linearity\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(512, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rCHBBgRhjiIy"
      },
      "outputs": [],
      "source": [
        "class BarlowTwins(nn.Module):\n",
        "    '''\n",
        "    Full Barlow Twins model with encoder, projector and loss\n",
        "    '''\n",
        "    def __init__(self, encoder, projector, lambd):\n",
        "        '''\n",
        "        :param encoder: encoder network\n",
        "        :param projector: projector network\n",
        "        :param lambd: tradeoff function (hyper-parameter)\n",
        "        '''\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.projector = projector\n",
        "        self.lambd = lambd     \n",
        "\n",
        "        # normalization layer for the representations z1 and z2\n",
        "        self.bn = nn.BatchNorm1d(128, affine=False)\n",
        "\n",
        "    def forward(self, y1, y2):\n",
        "        z1 = self.encoder(y1)\n",
        "        z2 = self.encoder(y2)\n",
        "        z1 = self.projector(z1)\n",
        "        z2 = self.projector(z2)\n",
        "\n",
        "        return barlow_loss(z1, z2, self.bn, self.lambd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UGOkjVCyjiIy"
      },
      "outputs": [],
      "source": [
        "cifar_train_mean = [125.30691805, 122.95039414, 113.86538318]\n",
        "cifar_train_std = [62.99321928, 62.08870764, 66.70489964]\n",
        "\n",
        "class Transform:\n",
        "    def __init__(self, t1, t2):\n",
        "        '''\n",
        "        :param t1: Transforms to be applied to first input\n",
        "        :param t2: Transforms to be applied to second input\n",
        "        '''\n",
        "        self.t1 = transforms.Compose([\n",
        "                t1,\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=cifar_train_mean, std=cifar_train_std)\n",
        "            ])\n",
        "        self.t2 = transforms.Compose([\n",
        "                t2,\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=cifar_train_mean, std=cifar_train_std)\n",
        "            ])\n",
        "\n",
        "    def __call__(self, x):\n",
        "        y1 = self.t1(x)\n",
        "        y2 = self.t2(x)\n",
        "        return y1, y2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ziXv_QixjiIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beec7d6b-e881-49a0-ca2c-ef128f0461ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 7.610368251800537\n",
            "Epoch: 2, Loss: 8.644915580749512\n",
            "Epoch: 3, Loss: 5.734394073486328\n",
            "Epoch: 4, Loss: 5.0028839111328125\n",
            "Epoch: 5, Loss: 5.47348690032959\n",
            "Epoch: 6, Loss: 5.095256328582764\n",
            "Epoch: 7, Loss: 5.4128570556640625\n",
            "Epoch: 8, Loss: 5.202373027801514\n",
            "Epoch: 9, Loss: 5.410131454467773\n",
            "Epoch: 10, Loss: 4.758655548095703\n"
          ]
        }
      ],
      "source": [
        "# Hyper-parameters\n",
        "EPOCHS = 10\n",
        "LR = 0.001\n",
        "BATCH = 256\n",
        "LAMBDA = 5e-3\n",
        "\n",
        "# Initialize encoder, projector and full model\n",
        "encoder = models.resnet18(pretrained=False)\n",
        "encoder.fc = nn.Identity() # removes the 1000-dimensional classification layer\n",
        "projector = Projector()\n",
        "twins = BarlowTwins(encoder, projector, LAMBDA).cuda()\n",
        "\n",
        "# Dataset and optimizer\n",
        "dataset = datasets.CIFAR10(root='./data', train=True, transform=Transform(t1, t2))\n",
        "loader = torch.utils.data.DataLoader(dataset,\n",
        "                                        batch_size=BATCH,\n",
        "                                        num_workers=4, # For some students, this cell took >1h to run. But when they used num_workers=0 it worked\n",
        "                                        shuffle=True)\n",
        "optimizer = torch.optim.Adam(twins.parameters(), lr=LR)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    for batch_idx, ((x1,x2), _) in enumerate(loader):\n",
        "        loss = twins(x1.cuda(), x2.cuda())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch: {epoch + 1}, Loss: {float(loss)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_SAMPLES = 1000\n",
        "\n",
        "# 1000 random (image, label) pairs from train set\n",
        "train_indices = random.sample(range(len(train_set)), k=NUM_SAMPLES)\n",
        "train_subset = train_set.data[train_indices]\n",
        "train_subset_labels = np.array(train_set.targets)[train_indices]\n",
        "\n",
        "# 1000 random (image, label) pairs from validation set\n",
        "val_indices = random.sample(range(len(val_set)), k=NUM_SAMPLES)\n",
        "val_subset = val_set.data[val_indices]\n",
        "val_subset_labels = np.array(val_set.targets)[val_indices]"
      ],
      "metadata": {
        "id": "Jb6a-ymWpVt8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0ZI9QcQDjiIp"
      },
      "outputs": [],
      "source": [
        "# We calculate this for each one step of validation. We take one validation sample and look into all used training samples to find out\n",
        "# K number of training samples with lowest distance (L1) to validation sample\n",
        "# We count how many of those K samples belonge to each class (here we have 10 classes) and return the class with highest count (where majority of K fell)\n",
        "\n",
        "\n",
        "def predict_knn(sample, train_data, train_labels, k):\n",
        "    '''\n",
        "    returns the predicted label for a specific validation sample\n",
        "    \n",
        "    :param sample: single example from validation set\n",
        "    :param train_data: full training set as a single array\n",
        "    :param train_labels: full set of training labels and a single array\n",
        "    :param k: number of nearest neighbors used for k-NN voting\n",
        "    '''\n",
        "    data = train_data.reshape(NUM_SAMPLES, -1)\n",
        "    label_count = np.zeros(10)            # because dataset used has 10 classes\n",
        "    dist = np.sum(np.abs(sample.flatten() - data), axis=1)\n",
        "    idx = np.argpartition(dist,k)         # partitions and sorts dist from small to large valued k chunks \n",
        "    min_ind = idx[:k]                     # we take only first k chunk, as it containes lowest values (smalest distances between one validation and all test examples)\n",
        "    for x in min_ind:\n",
        "        label_count[train_labels[x]] +=1\n",
        "    return np.argmax(label_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CcsWRz8_jiI0"
      },
      "outputs": [],
      "source": [
        "# Dataloaders for extracting self-supervised features\n",
        "test_transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=cifar_train_mean, std=cifar_train_std)\n",
        "            ])\n",
        "\n",
        "train_set = datasets.CIFAR10(root='./data', train=True, transform=test_transform)\n",
        "val_set = datasets.CIFAR10(root='./data', train=False, transform=test_transform)\n",
        "\n",
        "train_subset_torch = torch.utils.data.Subset(train_set, train_indices)\n",
        "val_subset_torch = torch.utils.data.Subset(val_set, val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_subset_torch,\n",
        "                                        batch_size=NUM_SAMPLES,\n",
        "                                        shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(val_subset_torch,\n",
        "                                        batch_size=NUM_SAMPLES,\n",
        "                                        shuffle=False)\n",
        "\n",
        "# Extract features with the trained encoder\n",
        "# We use a single batch of size 1000\n",
        "for batch in train_loader:\n",
        "    train_features = encoder(batch[0].cuda()).data.cpu().numpy()\n",
        "\n",
        "for batch in val_loader:\n",
        "    val_features = encoder(batch[0].cuda()).data.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-HWl7emrjiI0"
      },
      "outputs": [],
      "source": [
        "predictions_7 = []\n",
        "predictions_13 = []\n",
        "predictions_19 = []\n",
        "for sample in val_features:\n",
        "    predictions_7.append(predict_knn(sample, train_features, train_subset_labels, k=7))\n",
        "    predictions_13.append(predict_knn(sample, train_features, train_subset_labels, k=13))\n",
        "    predictions_19.append(predict_knn(sample, train_features, train_subset_labels, k=19))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dQNQylxgjiI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39938ff3-d805-4c91-9517-e604114d4234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-NN accuracy (k=7): 31.8%\n",
            "k-NN accuracy (k=13): 31.5%\n",
            "k-NN accuracy (k=19): 32.300000000000004%\n"
          ]
        }
      ],
      "source": [
        "matches_7 = (np.array(predictions_7) == val_subset_labels)\n",
        "accuracy_7 = np.sum(matches_7)/NUM_SAMPLES * 100\n",
        "print(f\"k-NN accuracy (k=7): {accuracy_7}%\")\n",
        "\n",
        "matches_13 = (np.array(predictions_13) == val_subset_labels)\n",
        "accuracy_13 = np.sum(matches_13)/NUM_SAMPLES * 100\n",
        "print(f\"k-NN accuracy (k=13): {accuracy_13}%\")\n",
        "\n",
        "matches_19 = (np.array(predictions_19) == val_subset_labels)\n",
        "accuracy_19 = np.sum(matches_19)/NUM_SAMPLES * 100\n",
        "print(f\"k-NN accuracy (k=19): {accuracy_19}%\")"
      ]
    }
  ]
}