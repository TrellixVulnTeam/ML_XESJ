{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9WtUP6B2nSR"
      },
      "source": [
        "read the paper --> Occupancy Networks: Learning 3D Reconstruction in Function Space https://arxiv.org/abs/1812.03828"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l303j6MMNMgP",
        "outputId": "505ca52d-3ef2-4b23-f70d-90fc088f626b"
      },
      "outputs": [],
      "source": [
        "!pip install livelossplot --quiet\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from livelossplot import PlotLosses\n",
        "from skimage.measure import marching_cubes_lewiner as marching_cubes    # Lewiner et al. algorithm is faster, resolves ambiguities, and guarantees topologically correct results\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# set random seed for reproducability\n",
        "np.random.seed(42)\n",
        "\n",
        "data_dir = 'data'\n",
        "out_dir = 'output'\n",
        "\n",
        "for d in [data_dir, out_dir]:\n",
        "  os.makedirs(d, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBC8twe9RHoJ"
      },
      "outputs": [],
      "source": [
        "#  points.npz download here: https://1drv.ms/u/s!AhnVhbVlzYkKgQeFmSuewkQcEJy_?e=ycVHcx\n",
        "# !wget is not a good idea with onedrive "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "v6JhqC2YqCNS"
      },
      "outputs": [],
      "source": [
        "def load_data(file_path):\n",
        "  ''' Load points and occupancy values from file.\n",
        "\n",
        "  Args:\n",
        "  file_path (string): path to file\n",
        "  '''\n",
        "  data_dict = np.load(file_path)\n",
        "  points = data_dict['points']\n",
        "  occupancies = data_dict['occupancies']\n",
        "\n",
        "  # Unpack data format of occupancies\n",
        "  occupancies = np.unpackbits(occupancies)[:points.shape[0]]\n",
        "  occupancies = occupancies.astype(np.float32)\n",
        "\n",
        "  # Align z-axis with top of object\n",
        "  points = np.stack([points[:, 0], -points[:, 2], points[:, 1]], 1)\n",
        "\n",
        "  return points, occupancies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "z-Hw2MmhrMdg"
      },
      "outputs": [],
      "source": [
        "def visualize_occupancy(points, occupancies, n=50000):\n",
        "  ''' Visualize points and occupancy values.\n",
        "\n",
        "  Args:\n",
        "  points (torch.Tensor or np.ndarray): 3D coordinates of the points\n",
        "  occupancies (torch.Tensor or np.ndarray): occupancy values for the points\n",
        "  n (int): maximum number of points to visualize\n",
        "  '''\n",
        "  # if needed convert torch.tensor to np.ndarray\n",
        "  if isinstance(points, torch.Tensor):\n",
        "    points = points.detach().cpu().numpy()\n",
        "  if isinstance(occupancies, torch.Tensor):\n",
        "    occupancies = occupancies.detach().cpu().numpy()\n",
        "\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "  n = min(len(points), n)\n",
        "\n",
        "  # visualize a random subset of n points\n",
        "  idcs = np.random.randint(0, len(points), n)\n",
        "  points = points[idcs]\n",
        "  occupancies = occupancies[idcs]\n",
        "\n",
        "  # define colors\n",
        "  red = np.array([1,0,0,0.5]).reshape(1, 4).repeat(n,0)     # plot occupied points in red with alpha=0.5\n",
        "  blue = np.array([0,0,1,0.01]).reshape(1, 4).repeat(n,0)   # plot free points in blue with alpha=0.01\n",
        "  occ = occupancies.reshape(n, 1).repeat(4, 1)              # reshape to RGBA format to determine color\n",
        "\n",
        "  color = np.where(occ == 1, red, blue)                     # occ=1 -> red, occ=0 -> blue\n",
        "  \n",
        "  # plot the points\n",
        "  ax.scatter(*points.transpose(), color=color)\n",
        "\n",
        "  # make it pretty\n",
        "  ax.set_xlabel('X')\n",
        "  ax.set_ylabel('Y')\n",
        "  ax.set_zlabel('Z')\n",
        "  \n",
        "  ax.set_xlim(-0.5, 0.5)\n",
        "  ax.set_ylim(-0.5, 0.5)\n",
        "  ax.set_zlim(-0.5, 0.5)\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "FXETH9VEts2d",
        "outputId": "a4bf29ad-5606-46d9-816b-33cc8181b3c9"
      },
      "outputs": [],
      "source": [
        "points, occupancies = load_data('./points.npz')\n",
        "visualize_occupancy(points, occupancies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "mjOtJHwiZ1AE"
      },
      "outputs": [],
      "source": [
        "def get_train_val_split(points, occupancies):\n",
        "  ''' Split data into train and validation set.\n",
        "  \n",
        "  Args:\n",
        "  points (torch.Tensor or np.ndarray): 3D coordinates of the points\n",
        "  occupancies (torch.Tensor or np.ndarray): occupancy values for the points\n",
        "  '''\n",
        "  n_train = int(0.8*len(points))\n",
        "  data = np.concatenate([points, occupancies.reshape(-1, 1)], 1)\n",
        "  np.random.shuffle(data)     # randomly shuffles data along first axis\n",
        "\n",
        "  train_data, val_data = np.split(data, [n_train])\n",
        "  train_points, train_occs = train_data[:, :3], train_data[:, 3]\n",
        "  val_points, val_occs = val_data[:, :3], val_data[:, 3]\n",
        "\n",
        "  # this converts the points and labels from numpy.ndarray to a pytorch dataset\n",
        "  train_set = torch.utils.data.TensorDataset(torch.from_numpy(train_points), torch.from_numpy(train_occs))\n",
        "  val_set = torch.utils.data.TensorDataset(torch.from_numpy(val_points), torch.from_numpy(val_occs))\n",
        "  return train_set, val_set\n",
        "\n",
        "train_set, val_set = get_train_val_split(points, occupancies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ir9NduT509eK"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=batch_size, num_workers=1, shuffle=True, drop_last=True       # randomly shuffle the training data and potentially drop last batch\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set, batch_size=batch_size, num_workers=1, shuffle=False, drop_last=False        # do not shuffle validation set and do not potentially drop last batch\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "_lpSf0CT8EqS",
        "outputId": "77171ef9-9285-438d-b061-4aaf5a0fdac7"
      },
      "outputs": [],
      "source": [
        "for loader in [train_loader, val_loader]:\n",
        "  check_points, check_occs = [], []\n",
        "  \n",
        "  for pts, occs in train_loader:\n",
        "    check_points.extend(pts)\n",
        "    check_occs.extend(occs)\n",
        "    if len(check_points) >= 10000:      # only visualize some points\n",
        "      break\n",
        "  \n",
        "  check_points, check_occs = torch.stack(check_points), torch.stack(check_occs)\n",
        "  visualize_occupancy(check_points, check_occs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "U7VrlssHUIO-"
      },
      "outputs": [],
      "source": [
        "class OccNet(nn.Module):\n",
        "  \"\"\" Network to predict an occupancy value for every 3D location. \n",
        "  \n",
        "  Args:\n",
        "  size_h (int): hidden dimension\n",
        "  n_hidden (int): number of hidden layers\n",
        "  \"\"\"\n",
        "  def __init__(self, size_h=64, n_hidden=4):\n",
        "    super().__init__()\n",
        "    # Attributes\n",
        "    size_in = 3\n",
        "    size_out = 1\n",
        "    actvn = nn.ReLU()\n",
        "\n",
        "    # Modules\n",
        "    layers = []\n",
        "\n",
        "    # first layer\n",
        "    layers.extend([\n",
        "      nn.Linear(size_in, size_h),\n",
        "      actvn,\n",
        "    ])\n",
        "\n",
        "    # hidden layers\n",
        "    for _ in range(n_hidden):\n",
        "      layers.extend([\n",
        "        nn.Linear(size_h, size_h),\n",
        "        actvn,\n",
        "      ])\n",
        "    \n",
        "    # last layer\n",
        "    layers.append(nn.Linear(size_h, size_out))\n",
        "\n",
        "    self.main = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, pts):\n",
        "    return self.main(pts).squeeze(-1)       # squeeze dimension of the single output value\n",
        "\n",
        "model = OccNet(size_h=64, n_hidden=4)\n",
        "\n",
        "# put the model on the GPU to accelerate training\n",
        "if torch.cuda.is_available():\n",
        "  model = model.cuda()\n",
        "else:\n",
        "  print('Fall back to CPU - GPU usage is recommended, e.g. using Google Colab.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "TIaNN--tb0U0"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss(reduction='none')    # binary cross entropy + log  --> same as softargmax\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "GPLyeS9KXFcs",
        "outputId": "b040fc69-480e-4d11-fb73-36dfd27b6180"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, optimizer, criterion, nepochs=15, eval_every=100, out_dir='output'):\n",
        "  \n",
        "  liveloss = PlotLosses()   # to plot training progress\n",
        "  losses = {'loss': None,\n",
        "            'val_loss': None}\n",
        "\n",
        "  best = float('inf')\n",
        "  it = 0\n",
        "  for epoch in range(nepochs):\n",
        "\n",
        "    losses['loss'] = []       # initialize emtpy container for training losses\n",
        "    for pts, occ in train_loader:\n",
        "      it += 1\n",
        "\n",
        "      # put data on GPU\n",
        "      if torch.cuda.is_available():\n",
        "        pts, occ = pts.cuda(), occ.cuda()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      scores = model(pts)\n",
        "      loss = criterion(scores, occ).mean()\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      losses['loss'].append(loss.item())\n",
        "\n",
        "      if (it == 1) or (it % eval_every == 0):\n",
        "        \n",
        "        with torch.no_grad():\n",
        "          val_loss = []\n",
        "          for val_pts, val_occ in val_loader:\n",
        "            # put data on GPU\n",
        "            if torch.cuda.is_available():\n",
        "              val_pts, val_occ = val_pts.cuda(), val_occ.cuda()\n",
        "\n",
        "            val_scores = model(val_pts)\n",
        "            val_loss_i = criterion(val_scores, val_occ)\n",
        "          \n",
        "            val_loss.extend(val_loss_i)\n",
        "          val_loss = torch.stack(val_loss).mean().item()\n",
        "          \n",
        "          if val_loss < best:     # keep track of best model\n",
        "            best = val_loss\n",
        "            torch.save(model.state_dict(), os.path.join(out_dir, 'model_best.pt'))\n",
        "\n",
        "    # update liveplot with latest values\n",
        "    losses['val_loss'] = val_loss\n",
        "    losses['loss'] = np.mean(losses['loss'])     # average over all training losses\n",
        "    liveloss.update(losses)\n",
        "    liveloss.send()\n",
        "\n",
        "train_model(model, train_loader, val_loader, optimizer, criterion, nepochs=25, eval_every=100, out_dir=out_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkfMK6XjSqj2",
        "outputId": "e1d42fdb-4a7c-49c7-f81c-cdd02cc5c431"
      },
      "outputs": [],
      "source": [
        "def make_grid(xmin, xmax, resolution):\n",
        "  \"\"\" Create equidistant points on 3D grid (cube shaped).\n",
        "  \n",
        "  Args:\n",
        "  xmin (float): minimum for x,y,z\n",
        "  xmax (float): number of hidden layers\n",
        "  \"\"\"\n",
        "  grid_1d = torch.linspace(xmin, xmax, resolution)\n",
        "  grid_3d = torch.stack(torch.meshgrid(grid_1d, grid_1d, grid_1d), -1)\n",
        "  return grid_3d.flatten(0, 2)     # return as flattened tensor: RxRxRx3 -> (R^3)x3\n",
        "\n",
        "resolution = 128          # use 128 grid points in each of the three dimensions -> 128^3 query points\n",
        "grid = make_grid(-0.5, 0.5, resolution)\n",
        "\n",
        "# wrap query points in data loader\n",
        "batch_size = 128\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    grid, batch_size=128, num_workers=1, shuffle=False, drop_last=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snoCKaQlgc-S",
        "outputId": "b2bcf02d-11a7-41ec-b0eb-8022bc45eebb"
      },
      "outputs": [],
      "source": [
        "weights_best = torch.load(os.path.join(out_dir, 'model_best.pt'))     # we saved the best model there in the training loop\n",
        "model.load_state_dict(weights_best)\n",
        "\n",
        "grid_values = []\n",
        "with torch.no_grad():\n",
        "  for pts in tqdm(test_loader, desc='Evaluate occupancy of grid points', position=0, leave=True):\n",
        "    if torch.cuda.is_available():\n",
        "        pts = pts.cuda()\n",
        "    grid_values.extend(model(pts).cpu())\n",
        "\n",
        "grid_values = torch.stack(grid_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "MFwZKlSMOmqj",
        "outputId": "55cf26e5-3127-465e-99b6-974f12f14689"
      },
      "outputs": [],
      "source": [
        "grid_occupancies = grid_values > 0.       # convert model scores to classification score\n",
        "visualize_occupancy(grid, grid_occupancies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "tOWM03jRN8mw",
        "outputId": "a5fd2bad-d41d-4772-d433-bd4a8026746b"
      },
      "outputs": [],
      "source": [
        "# extract mesh with Marching Cubes\n",
        "threshold = 0. # because grid values are model scores\n",
        "assert (grid_values.min() <= threshold) and (grid_values.max() >= threshold), \"Threshold is not in range of predicted values\"\n",
        "\n",
        "vertices, faces, _, _ = marching_cubes(grid_values.reshape(resolution, resolution, resolution).numpy(), \n",
        "                                                  threshold, \n",
        "                                                  spacing=(1/(resolution-1), 1/(resolution-1), 1/(resolution-1)),\n",
        "                                                  allow_degenerate=False)\n",
        "\n",
        "# plot mesh\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.plot_trisurf(vertices[:, 0], vertices[:,1], triangles=faces, Z=vertices[:,2])\n",
        "\n",
        "ax.set_xlim(0, 1)\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_zlim(0, 1)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
