{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Control Generation by Pretrained Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "GWgOnFMjFvib"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchvision\n",
        "\n",
        "import os\n",
        "import gdown                             \n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# import shutil\n",
        "# shutil.rmtree('./data')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def device():\n",
        "  if torch.cuda.is_available():\n",
        "    return torch.device('cuda')\n",
        "  else:\n",
        "    return torch.device('cpu')\n",
        "\n",
        "device = device()\n",
        "\n",
        "def todevice(data_model, device):\n",
        "  if isinstance(data_model, (list, tuple)):\n",
        "    return [todevice(i, device) for i in data_model]\n",
        "  return data_model.to(device, non_blocking=True)\n",
        "\n",
        "class DataDeviceLoader():\n",
        "  def __init__(self, dataloader, device):\n",
        "    self.dataloader = dataloader   \n",
        "    self.device = device\n",
        "\n",
        "  def __iter__(self):\n",
        "    for batch in self.dataloader:\n",
        "      yield todevice(batch, self.device)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.dataloader)"
      ],
      "metadata": {
        "id": "z8D4f_V2Mo3Z"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_root = 'data/celeba'\n",
        "dataset_folder = f'{dataset_root}/img_align_celeba'\n",
        "download_path = f'{dataset_root}/img_align_celeba.zip'\n",
        "\n",
        "if not os.path.exists(dataset_root):\n",
        "  os.makedirs(dataset_root)\n",
        "  os.makedirs(dataset_folder)\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1cNIac61PSA_LqDFYFUeyaQYekYPc75NH'\n",
        "gdown.download(url, download_path, quiet=False)\n",
        "\n",
        "with zipfile.ZipFile(download_path, 'r') as ziphandler:\n",
        "  ziphandler.extractall(dataset_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdEyuNnwYDyZ",
        "outputId": "364a6640-f051-4771-e4e1-4010ead25737"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cNIac61PSA_LqDFYFUeyaQYekYPc75NH\n",
            "To: /content/data/celeba/img_align_celeba.zip\n",
            "100%|██████████| 1.44G/1.44G [00:08<00:00, 178MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, inputchannels=3, imagesize=64, classes=10):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        self.block(inputchannels, imagesize),\n",
        "        self.block(imagesize, imagesize*2),\n",
        "        self.block(imagesize*2, imagesize*4, stride=3),        \n",
        "        self.block(imagesize*4, classes, lastlayer=True),\n",
        "    )\n",
        "  def block(self, inputchannels, outputchannels, kernelsize=4, stride=2, lastlayer=False):\n",
        "    if lastlayer:\n",
        "      return nn.Sequential(\n",
        "          nn.Conv2d(inputchannels, outputchannels, kernelsize, stride),\n",
        "          )\n",
        "    else:\n",
        "      return nn.Sequential(\n",
        "          nn.Conv2d(inputchannels, outputchannels, kernelsize, stride),\n",
        "          nn.BatchNorm2d(outputchannels),\n",
        "          nn.leakyReLU(0.2, inplace=True),\n",
        "          )\n",
        "\n",
        "  def forward(self, images):\n",
        "    predictions = self.model(images)\n",
        "    return predictions.view(predictions.size(0), -1)                       #the same predictions.shape[0] or len(predictions)\n",
        "\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, latentsize=100, imagesize=64, RGBchannels=3):\n",
        "    super(Generator, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        self.block(latentsize, imagesize*8),\n",
        "        self.block(imagesize*8, imagesize*4),\n",
        "        self.block(imagesize*4, imagesize*2), \n",
        "        self.block(imagesize*2, imagesize, kernelsize=4),         \n",
        "        self.block(imagesize*2, RGBchannels, lastlayer=True),\n",
        "    )\n",
        "  def block(self, inputchannels, outputchannels, kernelsize=3, stride=2, lastlayer=False):\n",
        "    if lastlayer:\n",
        "      return nn.Sequential(\n",
        "          nn.ConvTranspose2d(inputchannels, outputchannels, kernelsize, stride),\n",
        "          nn.Tanh(),\n",
        "          )\n",
        "    else:\n",
        "      return nn.Sequential(\n",
        "          nn.ConvTranspose2d(inputchannels, outputchannels, kernelsize, stride),\n",
        "          nn.BatchNorm2d(outputchannels),\n",
        "          nn.ReLU(True),\n",
        "          )\n",
        "\n",
        "  def forward(self, latentinput):\n",
        "    noisevector = latentinput.view(latentinput.size(0), self.latentsize, 1, 1)\n",
        "    return self.model(noisevector)                    "
      ],
      "metadata": {
        "id": "CRCNkmYcPqyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator().to(device)\n",
        "generator.load_state_dict(torch.load('Gen_CelebA.pth', map_location=torch.device(device))['generator'])\n",
        "\n",
        "discriminator = Discriminator(classes=40).to(device)\n",
        "discriminator.load_state_dict(torch.load('Dis_CelebA.pth', map_location=torch.device(device))['discriminator'])\n",
        "\n",
        "optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
        "\n",
        "batchsize = 128\n",
        "latentsize = 100"
      ],
      "metadata": {
        "id": "Xu9GWYiERuTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. optimizing for particular nois vectors to achieve special featured images without trying to disentangle different features that may be entangled with target feature\n",
        "\n",
        "features = [\"5oClockShadow\", \"ArchedEyebrows\", \"Attractive\", \"BagsUnderEyes\", \"Bald\", \"Bangs\",\n",
        "\"BigLips\", \"BigNose\", \"BlackHair\", \"BlondHair\", \"Blurry\", \"BrownHair\", \"BushyEyebrows\", \"Chubby\",\n",
        "\"DoubleChin\", \"Eyeglasses\", \"Goatee\", \"GrayHair\", \"HeavyMakeup\", \"HighCheekbones\", \"Male\", \n",
        "\"MouthSlightlyOpen\", \"Mustache\", \"NarrowEyes\", \"NoBeard\", \"OvalFace\", \"PaleSkin\", \"PointyNose\", \n",
        "\"RecedingHairline\", \"RosyCheeks\", \"Sideburn\", \"Smiling\", \"StraightHair\", \"WavyHair\", \"WearingEarrings\", \n",
        "\"WearingHat\", \"WearingLipstick\", \"WearingNecklace\", \"WearingNecktie\", \"Young\"]\n",
        "\n",
        "targetfeatureindex = features.index['Young']\n",
        "\n",
        "history = []\n",
        "latentinputnoise = torch.randn(batchsize, latentsize, device=device).requires_grad_()\n",
        "for i in range(10):\n",
        "  optimizer.zero_grad()\n",
        "  fake = generator(latentinputnoise)\n",
        "  history += [fake]\n",
        "  predictions = discriminator(fake)[:, targetfeatureindex].mean()\n",
        "  predictions.backward()\n",
        "  latentinputnoise.data = latentinputnoise + 0.1*latentinputnoise.grad      # latentinputnoise.data updates latentinputnoise and preserves for next iteration!!!\n"
      ],
      "metadata": {
        "id": "Jj7wdM9B2k0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. optimizing for particular nois vectors to achieve special featured images by trying to disentangle different features that may be entangled with target feature\n",
        "\n",
        "features = [\"5oClockShadow\", \"ArchedEyebrows\", \"Attractive\", \"BagsUnderEyes\", \"Bald\", \"Bangs\",\n",
        "\"BigLips\", \"BigNose\", \"BlackHair\", \"BlondHair\", \"Blurry\", \"BrownHair\", \"BushyEyebrows\", \"Chubby\",\n",
        "\"DoubleChin\", \"Eyeglasses\", \"Goatee\", \"GrayHair\", \"HeavyMakeup\", \"HighCheekbones\", \"Male\", \n",
        "\"MouthSlightlyOpen\", \"Mustache\", \"NarrowEyes\", \"NoBeard\", \"OvalFace\", \"PaleSkin\", \"PointyNose\", \n",
        "\"RecedingHairline\", \"RosyCheeks\", \"Sideburn\", \"Smiling\", \"StraightHair\", \"WavyHair\", \"WearingEarrings\", \n",
        "\"WearingHat\", \"WearingLipstick\", \"WearingNecklace\", \"WearingNecktie\", \"Young\"]\n",
        "\n",
        "targetfeatureindex = features.index['Young']\n",
        "otherfeatureindexes = [index != targetfeatureindex for index, _ in enumerate(features)]\n",
        "\n",
        "history = []\n",
        "latentinputnoise = torch.randn(batchsize, latentsize, device=device).requires_grad_()\n",
        "startingpredictions = discriminator(generator(latentinputnoise)).detach()\n",
        "\n",
        "for i in range(10):\n",
        "  optimizer.zero_grad()\n",
        "  fake = generator(latentinputnoise)\n",
        "  history += [fake]\n",
        "\n",
        "  targetfeature_score = discriminator(fake)[:, targetfeatureindex].mean()\n",
        "  nontargets_losses = startingpredictions[:, otherfeatureindexes] - discriminator(fake)[:, otherfeatureindexes]\n",
        "  nontargets_loss = torch.norm(nontargets_losses, dim=1).mean()*0.1             # 0.1 because we totally have 10 iterations here\n",
        "  final_score = targetfeature_score - nontargets_loss\n",
        "\n",
        "  final_score.backward()\n",
        "  latentinputnoise.data = latentinputnoise + 0.1*latentinputnoise.grad          # 0.1 because we totally have 10 iterations here   "
      ],
      "metadata": {
        "id": "8fu1twke9QHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check papers:\n",
        "\n",
        "https://arxiv.org/abs/1411.1784\n",
        "\n",
        "https://arxiv.org/abs/1907.10786"
      ],
      "metadata": {
        "id": "iHaFzx60QYXN"
      }
    }
  ]
}