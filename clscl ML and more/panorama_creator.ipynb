{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "GDBkWiYfiISM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Let's first define hyperparameters. In our case, we set the image height H and width H to 128 pixels.\n",
        "H, W = 128, 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRUecW60Tf_3"
      },
      "outputs": [],
      "source": [
        "# Load two images from which you want to create a panorama \n",
        "# just take one picture, than move your phone little bit toright and take another picture and load pictures in google colab files\n",
        "\n",
        "img1 = cv2.cvtColor(cv2.imread('./image_1.jpg'), cv2.COLOR_BGR2RGB)\n",
        "img2 = cv2.cvtColor(cv2.imread('./image_2.jpg'), cv2.COLOR_BGR2RGB)\n",
        "# Let's visualize the images\n",
        "f = plt.figure(figsize=(15, 5))\n",
        "ax1 = f.add_subplot(121)\n",
        "ax2 = f.add_subplot(122)\n",
        "ax1.imshow(img1)\n",
        "ax2.imshow(img2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "8JDKLMNuTf_3"
      },
      "outputs": [],
      "source": [
        "def get_keypoints(img1, img2):\n",
        "    orb = cv2.ORB_create(nfeatures=2000)\n",
        "\n",
        "    keypoints1, descriptors1 = orb.detectAndCompute(img1, None)\n",
        "    keypoints2, descriptors2 = orb.detectAndCompute(img2, None)\n",
        "    bf = cv2.BFMatcher_create(cv2.NORM_HAMMING)\n",
        "\n",
        "    # Find matching points\n",
        "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
        "    good = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.5 * n.distance:\n",
        "            good.append(m)\n",
        "    p_source = np.float32([ keypoints1[good_match.queryIdx].pt for good_match in good ]).reshape(-1,2)\n",
        "    p_target = np.float32([ keypoints2[good_match.trainIdx].pt for good_match in good ]).reshape(-1,2)\n",
        "    N = p_source.shape[0]\n",
        "    p_source = np.concatenate([p_source, np.ones((N, 1))], axis=-1)\n",
        "    p_target = np.concatenate([p_target, np.ones((N, 1))], axis=-1)\n",
        "    return p_source, p_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "fvtvKU9mTf_0"
      },
      "outputs": [],
      "source": [
        "def get_Ai(xi_vector, xi_prime_vector):\n",
        "    ''' Returns the A_i matrix discussed in the lecture for input vectors.\n",
        "    \n",
        "    Args:\n",
        "        xi_vector (array): the x_i vector in homogeneous coordinates\n",
        "        xi_vector_prime (array): the x_i_prime vector in homogeneous coordinates\n",
        "    '''\n",
        "    assert(xi_vector.shape == (3,) and xi_prime_vector.shape == (3,))\n",
        "    zero_vector = np.zeros((3,), dtype=np.float32)\n",
        "    xi, yi, wi = xi_prime_vector\n",
        "    \n",
        "    Ai = np.stack([\n",
        "        np.concatenate([zero_vector, -wi*xi_vector, yi*xi_vector]),\n",
        "        np.concatenate([wi*xi_vector, zero_vector, -xi*xi_vector]),\n",
        "        # np.concatenate([-yi*xi_vector, xi*xi_vector, zero_vector]) this is not needed, so we comment it out\n",
        "    ])\n",
        "    assert(Ai.shape == (2, 9))\n",
        "    return Ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "CQpqJHJETf_0"
      },
      "outputs": [],
      "source": [
        "def get_A(points_source, points_target):\n",
        "    ''' Returns the A matrix discussed in the lecture.\n",
        "    \n",
        "    Args:\n",
        "        points_source (array): 3D homogeneous points from source image\n",
        "        points_target (array): 3D homogeneous points from target image\n",
        "    '''\n",
        "    N = points_source.shape[0]\n",
        "    correspondence_pairs = zip(points_source, points_target)\n",
        "    \n",
        "    A = np.concatenate([get_Ai(p1, p2) for (p1, p2) in correspondence_pairs])\n",
        "    assert(A.shape == (2*N, 9))\n",
        "    return A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "WnauRnCITf_1"
      },
      "outputs": [],
      "source": [
        "def get_homography(points_source, points_target):\n",
        "    ''' Returns the homography H.\n",
        "    \n",
        "    Args:\n",
        "        points_source (array): 3D homogeneous points from source image\n",
        "        points_target (array): 3D homogeneous points from target image        \n",
        "    '''\n",
        "    A = get_A(points_source, points_target)\n",
        "    u, s, vh = np.linalg.svd(A)\n",
        "    H = vh[-1].reshape(3, 3)\n",
        "    return H"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "XmSFU0zxTf_2"
      },
      "outputs": [],
      "source": [
        "def stich_images(img1, img2, H):\n",
        "    ''' Stitches together the images via given homography H.\n",
        "\n",
        "    Args:\n",
        "        img1 (array): image 1\n",
        "        img2 (array): image 2\n",
        "        H (array): homography\n",
        "    '''\n",
        "\n",
        "    rows1, cols1 = img1.shape[:2]\n",
        "    rows2, cols2 = img2.shape[:2]\n",
        "\n",
        "    list_of_points_1 = np.float32([[0,0], [0, rows1],[cols1, rows1], [cols1, 0]]).reshape(-1, 1, 2)\n",
        "    temp_points = np.float32([[0,0], [0,rows2], [cols2,rows2], [cols2,0]]).reshape(-1,1,2)\n",
        "\n",
        "    list_of_points_2 = cv2.perspectiveTransform(temp_points, H)\n",
        "    list_of_points = np.concatenate((list_of_points_1,list_of_points_2), axis=0)\n",
        "\n",
        "    [x_min, y_min] = np.int32(list_of_points.min(axis=0).ravel() - 0.5)\n",
        "    [x_max, y_max] = np.int32(list_of_points.max(axis=0).ravel() + 0.5)\n",
        "\n",
        "    translation_dist = [-x_min,-y_min]\n",
        "\n",
        "    H_translation = np.array([[1, 0, translation_dist[0]], [0, 1, translation_dist[1]], [0, 0, 1]])\n",
        "\n",
        "    output_img = cv2.warpPerspective(img2, H_translation.dot(H), (x_max-x_min, y_max-y_min))\n",
        "    output_img[translation_dist[1]:rows1+translation_dist[1], translation_dist[0]:cols1+translation_dist[0]] = img1\n",
        "\n",
        "    return output_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBIpA_gzTf_4"
      },
      "outputs": [],
      "source": [
        "p_source, p_target = get_keypoints(img1, img2)\n",
        "H = get_homography(p_target, p_source)\n",
        "stiched_image = stich_images(img1, img2, H)\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "fig.suptitle(\"Stiched Panorama\")\n",
        "plt.imshow(stiched_image)"
      ]
    }
  ]
}